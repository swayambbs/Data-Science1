{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "id": "i7sv6j9w6tzy",
    "outputId": "b9cd8ec7-cdf0-4fb5-ddee-ae72f9fe6c35"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=pd.read_csv('data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "colab_type": "code",
    "id": "gccilFN06v5x",
    "outputId": "fb49299f-f096-45fe-d444-dd18516fff64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Benign 357\n",
      "Malignanat 212\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASYklEQVR4nO3df4xdZ33n8fcnTppES1oSeZI1tqld5C7rpI2zTL1sUVsKbZOl23WCADlSWXc3kvkjSFC1KyVdLaRU1tI2FFW0QXJKwCBKam1g46KUbbCgLIKNmUQmsR0sLJImxm48/ExCW69svvvHPX5yGY/tsZMzdzL3/ZKu7jnPeZ5zvhM585nnnHPPTVUhSRLAeaMuQJK0cBgKkqTGUJAkNYaCJKkxFCRJzfmjLuD5WLp0aa1atWrUZUjSi8qDDz74raqamG3bizoUVq1axdTU1KjLkKQXlSR/f6ptnj6SJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNS/qTzRLi9kT7/mZUZegBejl73qk1/33NlNIclGSXUm+mmRvkt/v2m9L8s0ku7vXG4bG3JrkQJL9Sa7tqzZJ0uz6nCkcBV5XVc8muQD4YpK/6ba9v6puH+6cZC2wEbgSeBnw2SQ/XVXHe6xRkjSkt5lCDTzbrV7QvU73hdAbgLur6mhVPQYcANb3VZ8k6WS9XmhOsiTJbuAIcH9VPdBtenuSh5PcleTSrm058OTQ8INd28x9bk4ylWRqenq6z/Ilaez0GgpVdbyq1gErgPVJrgI+CLwCWAccBt7Xdc9su5hln1urarKqJicmZn0cuCTpHM3LLalV9T3g88B1VfVUFxY/BO7kuVNEB4GVQ8NWAIfmoz5J0kCfdx9NJHlpt3wx8CvA15IsG+p2A7CnW94BbExyYZLVwBpgV1/1SZJO1ufdR8uAbUmWMAif7VX16SQfS7KOwamhx4G3AVTV3iTbgX3AMeBm7zySpPnVWyhU1cPANbO0v/U0Y7YAW/qqSZJ0ej7mQpLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKnpLRSSXJRkV5KvJtmb5Pe79suS3J/k6937pUNjbk1yIMn+JNf2VZskaXZ9zhSOAq+rqquBdcB1SV4N3ALsrKo1wM5unSRrgY3AlcB1wB1JlvRYnyRpht5CoQae7VYv6F4FbAC2de3bgOu75Q3A3VV1tKoeAw4A6/uqT5J0sl6vKSRZkmQ3cAS4v6oeAK6oqsMA3fvlXfflwJNDww92bTP3uTnJVJKp6enpPsuXpLHTayhU1fGqWgesANYnueo03TPbLmbZ59aqmqyqyYmJiReqVEkS83T3UVV9D/g8g2sFTyVZBtC9H+m6HQRWDg1bARyaj/okSQN93n00keSl3fLFwK8AXwN2AJu6bpuAe7vlHcDGJBcmWQ2sAXb1VZ8k6WTn97jvZcC27g6i84DtVfXpJF8Gtie5CXgCeDNAVe1Nsh3YBxwDbq6q4z3WJ0maobdQqKqHgWtmaf828PpTjNkCbOmrJknS6fmJZklSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqSmt1BIsjLJ55I8mmRvknd07bcl+WaS3d3rDUNjbk1yIMn+JNf2VZskaXbn97jvY8DvVNVDSS4BHkxyf7ft/VV1+3DnJGuBjcCVwMuAzyb56ao63mONkqQhvc0UqupwVT3ULT8DPAosP82QDcDdVXW0qh4DDgDr+6pPknSyebmmkGQVcA3wQNf09iQPJ7kryaVd23LgyaFhB5klRJJsTjKVZGp6errHqiVp/PQeCkleAtwDvLOqngY+CLwCWAccBt53oussw+ukhqqtVTVZVZMTExM9VS1J46nXUEhyAYNA+HhVfRKgqp6qquNV9UPgTp47RXQQWDk0fAVwqM/6JEk/qs+7jwJ8CHi0qv5kqH3ZULcbgD3d8g5gY5ILk6wG1gC7+qpPknSyPu8+eg3wVuCRJLu7tt8DbkyyjsGpoceBtwFU1d4k24F9DO5cutk7jyRpfvUWClX1RWa/TnDfacZsAbb0VZMk6fT8RLMkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNX1+89qLwqv+60dHXYIWoAf/+D+NugRpJJwpSJIaQ0GS1MwpFJLsnEubJOnF7bShkOSiJJcBS5NcmuSy7rUKeNkZxq5M8rkkjybZm+QdXftlSe5P8vXu/dKhMbcmOZBkf5Jrn/+PJ0k6G2eaKbwNeBB4Zfd+4nUv8OdnGHsM+J2q+tfAq4Gbk6wFbgF2VtUaYGe3TrdtI3AlcB1wR5Il5/JDSZLOzWlDoar+tKpWA79bVT9VVau719VV9WdnGHu4qh7qlp8BHgWWAxuAbV23bcD13fIG4O6qOlpVjwEHgPXn/JNJks7anG5JraoPJPl5YNXwmKqa0/2c3emma4AHgCuq6nA3/nCSy7tuy4H/OzTsYNc2c1+bgc0AL3/5y+dyeEnSHM0pFJJ8DHgFsBs43jUXcMZQSPIS4B7gnVX1dJJTdp2lrU5qqNoKbAWYnJw8absk6dzN9cNrk8DaqjqrX8JJLmAQCB+vqk92zU8lWdbNEpYBR7r2g8DKoeErgENnczxJ0vMz188p7AH+5dnsOIMpwYeAR6vqT4Y27QA2dcubGFy0PtG+McmFSVYDa4BdZ3NMSdLzM9eZwlJgX5JdwNETjVX1H08z5jXAW4FHkuzu2n4PeC+wPclNwBPAm7t97U2yHdjH4M6lm6vq+Mm7lST1Za6hcNvZ7riqvsjs1wkAXn+KMVuALWd7LEnSC2Oudx/9Xd+FSJJGb653Hz3Dc3cC/RhwAfCDqvrxvgqTJM2/uc4ULhleT3I9frBMkhadc3pKalX9L+B1L3AtkqQRm+vpozcOrZ7H4HMLfnBMkhaZud599BtDy8eAxxk8q0iStIjM9ZrCf+67EEnS6M31S3ZWJPlUkiNJnkpyT5IVfRcnSZpfc73Q/GEGj6F4GYMnl/511yZJWkTmGgoTVfXhqjrWvT4CTPRYlyRpBOYaCt9K8ptJlnSv3wS+3WdhkqT5N9dQ+C/AW4B/AA4DbwK8+CxJi8xcb0n9A2BTVX0XIMllwO0MwkKStEjMdabwsycCAaCqvsPg6zUlSYvIXEPhvCSXnljpZgpznWVIkl4k5vqL/X3Al5L8TwaPt3gLfu+BJC06c/1E80eTTDF4CF6AN1bVvl4rkyTNuzmfAupCwCCQpEXsnB6dLUlanAwFSVLTWygkuat7gN6eobbbknwzye7u9YahbbcmOZBkf5Jr+6pLknRqfc4UPgJcN0v7+6tqXfe6DyDJWmAjcGU35o4kS3qsTZI0i95Coaq+AHxnjt03AHdX1dGqegw4gN8BLUnzbhTXFN6e5OHu9NKJD8QtB54c6nOwaztJks1JppJMTU9P912rJI2V+Q6FDwKvANYxeLDe+7r2zNJ31u+ArqqtVTVZVZMTEz69W5JeSPMaClX1VFUdr6ofAnfy3Cmig8DKoa4rgEPzWZskaZ5DIcmyodUbgBN3Ju0ANia5MMlqYA2waz5rkyT1+FC7JJ8AXgssTXIQeDfw2iTrGJwaehx4G0BV7U2yncEnpo8BN1fV8b5qkyTNrrdQqKobZ2n+0Gn6b8GH7EnSSPmJZklSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqSmt1BIcleSI0n2DLVdluT+JF/v3i8d2nZrkgNJ9ie5tq+6JEmn1udM4SPAdTPabgF2VtUaYGe3TpK1wEbgym7MHUmW9FibJGkWvYVCVX0B+M6M5g3Atm55G3D9UPvdVXW0qh4DDgDr+6pNkjS7+b6mcEVVHQbo3i/v2pcDTw71O9i1nSTJ5iRTSaamp6d7LVaSxs1CudCcWdpqto5VtbWqJqtqcmJioueyJGm8zHcoPJVkGUD3fqRrPwisHOq3Ajg0z7VJ0tib71DYAWzqljcB9w61b0xyYZLVwBpg1zzXJklj7/y+dpzkE8BrgaVJDgLvBt4LbE9yE/AE8GaAqtqbZDuwDzgG3FxVx/uqTZI0u95CoapuPMWm15+i/xZgS1/1SJLObKFcaJYkLQCGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkhpDQZLUGAqSpMZQkCQ1hoIkqTEUJEmNoSBJas4fxUGTPA48AxwHjlXVZJLLgL8CVgGPA2+pqu+Ooj5JGlejnCn8clWtq6rJbv0WYGdVrQF2duuSpHm0kE4fbQC2dcvbgOtHWIskjaVRhUIBf5vkwSSbu7YrquowQPd++WwDk2xOMpVkanp6ep7KlaTxMJJrCsBrqupQksuB+5N8ba4Dq2orsBVgcnKy+ipQksbRSGYKVXWoez8CfApYDzyVZBlA935kFLVJ0jib91BI8i+SXHJiGfg1YA+wA9jUddsE3DvftUnSuBvF6aMrgE8lOXH8v6yqzyT5CrA9yU3AE8CbR1CbJI21eQ+FqvoGcPUs7d8GXj/f9UiSnrOQbkmVJI2YoSBJagwFSVJjKEiSGkNBktQYCpKkxlCQJDWGgiSpMRQkSY2hIElqDAVJUmMoSJIaQ0GS1BgKkqTGUJAkNYaCJKkxFCRJjaEgSWoMBUlSYyhIkpoFFwpJrkuyP8mBJLeMuh5JGicLKhSSLAH+HPj3wFrgxiRrR1uVJI2PBRUKwHrgQFV9o6r+H3A3sGHENUnS2Dh/1AXMsBx4cmj9IPBvhzsk2Qxs7lafTbJ/nmobB0uBb426iIUgt28adQn6Uf7bPOHdeSH28pOn2rDQQmG2n7Z+ZKVqK7B1fsoZL0mmqmpy1HVIM/lvc/4stNNHB4GVQ+srgEMjqkWSxs5CC4WvAGuSrE7yY8BGYMeIa5KksbGgTh9V1bEkbwf+N7AEuKuq9o64rHHiaTktVP7bnCepqjP3kiSNhYV2+kiSNEKGgiSpMRTGXJJK8rGh9fOTTCf59CjrkgCSHE+yO8lXkzyU5OdHXdNit6AuNGskfgBcleTiqvon4FeBb464JumEf6qqdQBJrgX+B/BLoy1pcXOmIIC/AX69W74R+MQIa5FO5ceB7466iMXOUBAMnjG1MclFwM8CD4y4HumEi7vTR18D/gL4g1EXtNh5+khU1cNJVjGYJdw32mqkHzF8+ujfAR9NclV5L31vnCnohB3A7XjqSAtUVX2ZwYPxJkZdy2LmTEEn3AV8v6oeSfLaURcjzZTklQyedPDtUdeymBkKAqCqDgJ/Ouo6pBkuTrK7Ww6wqaqOj7Kgxc7HXEiSGq8pSJIaQ0GS1BgKkqTGUJAkNYaCJKnxllSpk+Q24FkGz9j5QlV9doS1vGfUNWg8GQrSDFX1LmvQuPL0kcZakv+WZH+SzwL/qmv7SJI3dcvvSvKVJHuSbE2Srv3nkjyc5MtJ/jjJnq79t5J8Mslnknw9yR8NHevGJI90+/rDrm1Jd7w93bbfnqWG9ybZ1x3v9nn9D6Sx40xBYyvJq4CNwDUM/l94CHhwRrc/q6r3dP0/BvwH4K+BDwObq+pLSd47Y8y6bp9Hgf1JPgAcB/4QeBWDxz//bZLrgSeB5VV1VXeMl86o8TLgBuCVVVUzt0svNGcKGme/AHyqqv6xqp5m8FDAmX45yQNJHgFeB1zZ/WK+pKq+1PX5yxljdlbV96vqn4F9wE8CPwd8vqqmq+oY8HHgF4FvAD+V5ANJrgOenrGvp4F/Bv4iyRuBf3zeP7V0GoaCxt0pn/PSfb/EHcCbqupngDuBixg8g+d0jg4tH2cwC5l1TFV9F7ga+DxwM4PvDBjefgxYD9wDXA985gzHlp4XQ0Hj7AvADUkuTnIJ8Bsztl/UvX8ryUuAN0H7Rf5Mkld32zfO4VgPAL+UZGmSJQy+u+LvkiwFzquqe4D/Dvyb4UHdcX+iqu4D3sng1JTUG68paGxV1UNJ/grYDfw98H9mbP9ekjuBR4DHga8Mbb4JuDPJDxj8lf/9MxzrcJJbgc8xmDXcV1X3Jrka+HCSE3+g3Tpj6CXAvd2sJcBvn/UPKp0Fn5IqnYMkL6mqZ7vlW4BlVfWOEZclPW/OFKRz8+vdX/7nM5hl/NZoy5FeGM4UJEmNF5olSY2hIElqDAVJUmMoSJIaQ0GS1Px/nU/oS5OQ23IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.countplot(data['diagnosis'], label= 'Count')\n",
    "B,M = data['diagnosis'].value_counts()\n",
    "print('Benign', B)\n",
    "print('Malignanat', M)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XVCX3ELW6yJA"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Importing data\n",
    "del data['Unnamed: 32']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cB5fKA3u6ydw"
   },
   "outputs": [],
   "source": [
    "X = data.iloc[:, 2:].values\n",
    "y = data.iloc[:, 1].values\n",
    "\n",
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "y = labelencoder_X_1.fit_transform(y)\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "ZpAVng9I6yjY",
    "outputId": "f62b0b0e-acc7-4da5-b75d-f4ed58b21ad5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.15036482, -0.39064196, -1.12855021, ..., -0.75798367,\n",
       "        -0.01614761, -0.38503402],\n",
       "       [-0.93798972,  0.68051405, -0.94820146, ..., -0.60687023,\n",
       "         0.09669004, -0.38615797],\n",
       "       [ 0.574121  , -1.03333557,  0.51394098, ..., -0.02371948,\n",
       "        -0.20050207, -0.75144254],\n",
       "       ...,\n",
       "       [-1.32422924, -0.20048168, -1.31754581, ..., -0.97974953,\n",
       "        -0.71542314, -0.11978123],\n",
       "       [-1.24380987, -0.2245526 , -1.28007609, ..., -1.75401433,\n",
       "        -1.58157125, -1.00601779],\n",
       "       [-0.73694129,  1.14989702, -0.71226578, ..., -0.27460457,\n",
       "        -1.25895095,  0.21515662]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "BItiguG56ypQ",
    "outputId": "9c81a0c9-8d4a-4eb2-a2f5-a512e4473c6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20175604,  0.3290786 , -0.13086754, ...,  1.3893291 ,\n",
       "         1.08203284,  1.54029664],\n",
       "       [-0.25555773,  1.46763319, -0.31780437, ..., -0.83369364,\n",
       "        -0.73131577, -0.87732522],\n",
       "       [-0.02619262, -0.8407682 , -0.09175081, ..., -0.49483785,\n",
       "        -1.22080864, -0.92115937],\n",
       "       ...,\n",
       "       [ 1.71811488,  0.09318356,  1.7286186 , ...,  1.57630515,\n",
       "         0.20317063, -0.15406178],\n",
       "       [ 1.18859296,  0.34352115,  1.19333694, ...,  0.56019755,\n",
       "         0.26991966, -0.27320074],\n",
       "       [ 0.26263752, -0.58080224,  0.28459338, ..., -0.19383705,\n",
       "        -1.15564888,  0.11231497]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "l8hiTfZu7ELL",
    "outputId": "e8680904-9d55-41bb-de3b-b723b0abb475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: pyyaml in d:\\anaconda\\anaconda3\\lib\\site-packages (from keras) (5.3.1)\n",
      "Requirement already satisfied: numpy>=1.9.1 in d:\\anaconda\\anaconda3\\lib\\site-packages (from keras) (1.18.5)\n",
      "Requirement already satisfied: h5py in d:\\anaconda\\anaconda3\\lib\\site-packages (from keras) (2.10.0)\n",
      "Requirement already satisfied: scipy>=0.14 in d:\\anaconda\\anaconda3\\lib\\site-packages (from keras) (1.5.0)\n",
      "Requirement already satisfied: six in d:\\anaconda\\anaconda3\\lib\\site-packages (from h5py->keras) (1.15.0)\n",
      "Installing collected packages: keras\n",
      "Successfully installed keras-2.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "id": "rk7mSVwL-TlI",
    "outputId": "b0cdce1e-8f71-459a-c987-b5a3b7da1fc0"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "id": "UT8yTxdE-VBN",
    "outputId": "78a7b1cd-761f-41e5-b838-6269dc38d7a3"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dropout\n",
    "#adding the input and first hidden layer\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(16, kernel_initializer='uniform', activation='relu',input_dim=30))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "#adding the second hidden layer\n",
    "classifier.add(Dense(16, kernel_initializer='uniform', activation='relu'))\n",
    "classifier.add(Dropout(.2))\n",
    "\n",
    "#adding the output layer\n",
    "classifier.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "JSYz-acvpIf3",
    "outputId": "0ee814a3-72a3-47d3-bbd4-9475471b14bd"
   },
   "outputs": [],
   "source": [
    "classifier.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "dP06VafNpJQ2",
    "outputId": "fb877dfb-9b23-4b01-e278-8b32709e122a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "5/5 [==============================] - 0s 3ms/step - loss: 0.6900 - accuracy: 0.7099\n",
      "Epoch 2/150\n",
      "5/5 [==============================] - 0s 992us/step - loss: 0.6815 - accuracy: 0.8549\n",
      "Epoch 3/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.6686 - accuracy: 0.8879\n",
      "Epoch 4/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6485 - accuracy: 0.9165\n",
      "Epoch 5/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.6259 - accuracy: 0.9341\n",
      "Epoch 6/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5944 - accuracy: 0.9341\n",
      "Epoch 7/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.9473\n",
      "Epoch 8/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.9473\n",
      "Epoch 9/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.4721 - accuracy: 0.9538\n",
      "Epoch 10/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.4271 - accuracy: 0.9560\n",
      "Epoch 11/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.3716 - accuracy: 0.9626\n",
      "Epoch 12/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.3285 - accuracy: 0.9604\n",
      "Epoch 13/150\n",
      "5/5 [==============================] - 0s 599us/step - loss: 0.2952 - accuracy: 0.9692\n",
      "Epoch 14/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2568 - accuracy: 0.9626\n",
      "Epoch 15/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.2340 - accuracy: 0.9692\n",
      "Epoch 16/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.2051 - accuracy: 0.9714\n",
      "Epoch 17/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1828 - accuracy: 0.9736\n",
      "Epoch 18/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1674 - accuracy: 0.9758\n",
      "Epoch 19/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1548 - accuracy: 0.9736\n",
      "Epoch 20/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9758\n",
      "Epoch 21/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1393 - accuracy: 0.9736\n",
      "Epoch 22/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1227 - accuracy: 0.9824\n",
      "Epoch 23/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1196 - accuracy: 0.9780\n",
      "Epoch 24/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.1088 - accuracy: 0.9802\n",
      "Epoch 25/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.1062 - accuracy: 0.9802\n",
      "Epoch 26/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0989 - accuracy: 0.9802\n",
      "Epoch 27/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0989 - accuracy: 0.9802\n",
      "Epoch 28/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.1009 - accuracy: 0.9780\n",
      "Epoch 29/150\n",
      "5/5 [==============================] - 0s 918us/step - loss: 0.0918 - accuracy: 0.9824\n",
      "Epoch 30/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0934 - accuracy: 0.9824\n",
      "Epoch 31/150\n",
      "5/5 [==============================] - 0s 740us/step - loss: 0.0920 - accuracy: 0.9824\n",
      "Epoch 32/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0899 - accuracy: 0.9846\n",
      "Epoch 33/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0792 - accuracy: 0.9802\n",
      "Epoch 34/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0832 - accuracy: 0.9802\n",
      "Epoch 35/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0869 - accuracy: 0.9824\n",
      "Epoch 36/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0848 - accuracy: 0.9802\n",
      "Epoch 37/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0767 - accuracy: 0.9824\n",
      "Epoch 38/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0758 - accuracy: 0.9802\n",
      "Epoch 39/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0776 - accuracy: 0.9802\n",
      "Epoch 40/150\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0791 - accuracy: 0.9824\n",
      "Epoch 41/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0644 - accuracy: 0.9868\n",
      "Epoch 42/150\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0749 - accuracy: 0.9868\n",
      "Epoch 43/150\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 0.0704 - accuracy: 0.9868\n",
      "Epoch 44/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0689 - accuracy: 0.9868\n",
      "Epoch 45/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9868\n",
      "Epoch 46/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0682 - accuracy: 0.9824\n",
      "Epoch 47/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0599 - accuracy: 0.9868\n",
      "Epoch 48/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0661 - accuracy: 0.9846\n",
      "Epoch 49/150\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0704 - accuracy: 0.9868\n",
      "Epoch 50/150\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0660 - accuracy: 0.9868\n",
      "Epoch 51/150\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.0690 - accuracy: 0.9890\n",
      "Epoch 52/150\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0715 - accuracy: 0.9890\n",
      "Epoch 53/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0641 - accuracy: 0.9846\n",
      "Epoch 54/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0602 - accuracy: 0.9890\n",
      "Epoch 55/150\n",
      "5/5 [==============================] - 0s 872us/step - loss: 0.0711 - accuracy: 0.9868\n",
      "Epoch 56/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0661 - accuracy: 0.9890\n",
      "Epoch 57/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0683 - accuracy: 0.9890\n",
      "Epoch 58/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0587 - accuracy: 0.9868\n",
      "Epoch 59/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0615 - accuracy: 0.9890\n",
      "Epoch 60/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0656 - accuracy: 0.9890\n",
      "Epoch 61/150\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.0625 - accuracy: 0.9890\n",
      "Epoch 62/150\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0604 - accuracy: 0.9890\n",
      "Epoch 63/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0582 - accuracy: 0.9890\n",
      "Epoch 64/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0588 - accuracy: 0.9868\n",
      "Epoch 65/150\n",
      "5/5 [==============================] - 0s 829us/step - loss: 0.0580 - accuracy: 0.9868\n",
      "Epoch 66/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0632 - accuracy: 0.9890\n",
      "Epoch 67/150\n",
      "5/5 [==============================] - 0s 983us/step - loss: 0.0562 - accuracy: 0.9868\n",
      "Epoch 68/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0544 - accuracy: 0.9890\n",
      "Epoch 69/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0522 - accuracy: 0.9868\n",
      "Epoch 70/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0602 - accuracy: 0.9890\n",
      "Epoch 71/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0576 - accuracy: 0.9890\n",
      "Epoch 72/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0566 - accuracy: 0.9868\n",
      "Epoch 73/150\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0587 - accuracy: 0.9868\n",
      "Epoch 74/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0490 - accuracy: 0.9890\n",
      "Epoch 75/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0535 - accuracy: 0.9890\n",
      "Epoch 76/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0562 - accuracy: 0.9890\n",
      "Epoch 77/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0517 - accuracy: 0.9890\n",
      "Epoch 78/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0516 - accuracy: 0.9912\n",
      "Epoch 79/150\n",
      "5/5 [==============================] - 0s 998us/step - loss: 0.0533 - accuracy: 0.9890\n",
      "Epoch 80/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0621 - accuracy: 0.9890\n",
      "Epoch 81/150\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0535 - accuracy: 0.9868\n",
      "Epoch 82/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0589 - accuracy: 0.9868\n",
      "Epoch 83/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 0s 800us/step - loss: 0.0562 - accuracy: 0.9868\n",
      "Epoch 84/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0516 - accuracy: 0.9912\n",
      "Epoch 85/150\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0499 - accuracy: 0.9890\n",
      "Epoch 86/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0411 - accuracy: 0.9890\n",
      "Epoch 87/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0449 - accuracy: 0.9846\n",
      "Epoch 88/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0516 - accuracy: 0.9890\n",
      "Epoch 89/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0490 - accuracy: 0.9912\n",
      "Epoch 90/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0447 - accuracy: 0.9912\n",
      "Epoch 91/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0466 - accuracy: 0.9890\n",
      "Epoch 92/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0502 - accuracy: 0.9890\n",
      "Epoch 93/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0532 - accuracy: 0.9890\n",
      "Epoch 94/150\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0472 - accuracy: 0.9890\n",
      "Epoch 95/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0460 - accuracy: 0.9890\n",
      "Epoch 96/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0439 - accuracy: 0.9912\n",
      "Epoch 97/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0501 - accuracy: 0.9912\n",
      "Epoch 98/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0481 - accuracy: 0.9890\n",
      "Epoch 99/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9912\n",
      "Epoch 100/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0382 - accuracy: 0.9912\n",
      "Epoch 101/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0390 - accuracy: 0.9912\n",
      "Epoch 102/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0515 - accuracy: 0.9868\n",
      "Epoch 103/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0498 - accuracy: 0.9868\n",
      "Epoch 104/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0449 - accuracy: 0.9890\n",
      "Epoch 105/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0422 - accuracy: 0.9890\n",
      "Epoch 106/150\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0453 - accuracy: 0.9912\n",
      "Epoch 107/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0415 - accuracy: 0.9890\n",
      "Epoch 108/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0448 - accuracy: 0.9912\n",
      "Epoch 109/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0518 - accuracy: 0.9890\n",
      "Epoch 110/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0437 - accuracy: 0.9890\n",
      "Epoch 111/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0467 - accuracy: 0.9890\n",
      "Epoch 112/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0404 - accuracy: 0.9912\n",
      "Epoch 113/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0444 - accuracy: 0.9890\n",
      "Epoch 114/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0435 - accuracy: 0.9890\n",
      "Epoch 115/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0424 - accuracy: 0.9890\n",
      "Epoch 116/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0369 - accuracy: 0.9912\n",
      "Epoch 117/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0464 - accuracy: 0.9912\n",
      "Epoch 118/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0361 - accuracy: 0.9912\n",
      "Epoch 119/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0424 - accuracy: 0.9912\n",
      "Epoch 120/150\n",
      "5/5 [==============================] - 0s 803us/step - loss: 0.0453 - accuracy: 0.9912\n",
      "Epoch 121/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0458 - accuracy: 0.9890\n",
      "Epoch 122/150\n",
      "5/5 [==============================] - 0s 898us/step - loss: 0.0387 - accuracy: 0.9912\n",
      "Epoch 123/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0337 - accuracy: 0.9890\n",
      "Epoch 124/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0403 - accuracy: 0.9912\n",
      "Epoch 125/150\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0375 - accuracy: 0.9890\n",
      "Epoch 126/150\n",
      "5/5 [==============================] - 0s 837us/step - loss: 0.0373 - accuracy: 0.9890\n",
      "Epoch 127/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0389 - accuracy: 0.9868\n",
      "Epoch 128/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0403 - accuracy: 0.9912\n",
      "Epoch 129/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0388 - accuracy: 0.9912\n",
      "Epoch 130/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0399 - accuracy: 0.9912\n",
      "Epoch 131/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0352 - accuracy: 0.9912\n",
      "Epoch 132/150\n",
      "5/5 [==============================] - 0s 999us/step - loss: 0.0417 - accuracy: 0.9890\n",
      "Epoch 133/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0375 - accuracy: 0.9868\n",
      "Epoch 134/150\n",
      "5/5 [==============================] - 0s 997us/step - loss: 0.0383 - accuracy: 0.9890\n",
      "Epoch 135/150\n",
      "5/5 [==============================] - 0s 896us/step - loss: 0.0412 - accuracy: 0.9912\n",
      "Epoch 136/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0422 - accuracy: 0.9912\n",
      "Epoch 137/150\n",
      "5/5 [==============================] - 0s 799us/step - loss: 0.0370 - accuracy: 0.9912\n",
      "Epoch 138/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0358 - accuracy: 0.9912\n",
      "Epoch 139/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0372 - accuracy: 0.9912\n",
      "Epoch 140/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0354 - accuracy: 0.9912\n",
      "Epoch 141/150\n",
      "5/5 [==============================] - 0s 801us/step - loss: 0.0337 - accuracy: 0.9890\n",
      "Epoch 142/150\n",
      "5/5 [==============================] - 0s 953us/step - loss: 0.0392 - accuracy: 0.9912\n",
      "Epoch 143/150\n",
      "5/5 [==============================] - 0s 887us/step - loss: 0.0363 - accuracy: 0.9890\n",
      "Epoch 144/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 0.9912\n",
      "Epoch 145/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0320 - accuracy: 0.9912\n",
      "Epoch 146/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0372 - accuracy: 0.9912\n",
      "Epoch 147/150\n",
      "5/5 [==============================] - 0s 1000us/step - loss: 0.0355 - accuracy: 0.9912\n",
      "Epoch 148/150\n",
      "5/5 [==============================] - 0s 600us/step - loss: 0.0395 - accuracy: 0.9890\n",
      "Epoch 149/150\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 0.0317 - accuracy: 0.9912\n",
      "Epoch 150/150\n",
      "5/5 [==============================] - 0s 800us/step - loss: 0.0389 - accuracy: 0.9890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x19d37364340>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train, y_train, batch_size=100, epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "zqwAnlLxqmfl",
    "outputId": "031431ea-a5f9-40f8-ba97-55f8378a5fd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20175604,  0.3290786 , -0.13086754, ...,  1.3893291 ,\n",
       "         1.08203284,  1.54029664],\n",
       "       [-0.25555773,  1.46763319, -0.31780437, ..., -0.83369364,\n",
       "        -0.73131577, -0.87732522],\n",
       "       [-0.02619262, -0.8407682 , -0.09175081, ..., -0.49483785,\n",
       "        -1.22080864, -0.92115937],\n",
       "       ...,\n",
       "       [ 1.71811488,  0.09318356,  1.7286186 , ...,  1.57630515,\n",
       "         0.20317063, -0.15406178],\n",
       "       [ 1.18859296,  0.34352115,  1.19333694, ...,  0.56019755,\n",
       "         0.26991966, -0.27320074],\n",
       "       [ 0.26263752, -0.58080224,  0.28459338, ..., -0.19383705,\n",
       "        -1.15564888,  0.11231497]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mbZfCbJG6yua"
   },
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rm5zSOlp7BDP"
   },
   "outputs": [],
   "source": [
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "IcNQu9q17NT_",
    "outputId": "44d5cf64-8e22-4b5f-c3a3-d6448f4812e0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm,annot=True)\n",
    "plt.savefig('h.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_AF3xeeD7N8P",
    "outputId": "ba8958ab-8562-4019-f1e3-ba27d9668363"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.956140350877193"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First Accuracy after training\n",
    "(65+44)/114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ms7zBmimWK1a",
    "outputId": "bf79e442-750c-4d35-975a-af91f441c360"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64+44)/114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uitf1DEJWLKt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yTGnjepyWLZE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d6AbvNv0WLmN"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rp6XC7swWLyU"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tuJYCP9YWL_V"
   },
   "source": [
    "Better Optamization Techniques "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fqqMqjWg4UD_"
   },
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def built_classifier():\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(output_dim=16, init='uniform', activation='relu',input_dim=30))\n",
    "  classifier.add(Dense(output_dim=16, init='uniform', activation='relu'))\n",
    "  classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "  classifier.compile(optimizer=\"Adam\", loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = built_classifier, batch_size = 100, epochs=100)\n",
    "accuracies = cross_val_score(estimator = classifier, X = X_train, y=y_train, cv=10, n_jobs =-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "FeDk0lkF4aF0",
    "outputId": "d6a81101-ff0b-49f4-bf62-a252d0c48251"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 0.97826087, 0.95652175,\n",
       "       0.95555556, 1.        , 1.        , 0.97777778, 0.95555556])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zWaPQUy1KTLf",
    "outputId": "acb4f567-38ef-400b-9062-dd2dc14345f2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9823671519756317"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "HkHeQyvzKjOX",
    "outputId": "14d2936d-d798-4b27-a405-5dc4dcd1067a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01923075259494915"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "T90K7WfBKogC",
    "outputId": "22bc2f68-3ec1-451c-d945-14e57d23b58e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", input_dim=30, units=16, kernel_initializer=\"uniform\")`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=16, kernel_initializer=\"uniform\")`\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1, kernel_initializer=\"uniform\")`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "409/409 [==============================] - 0s 787us/step - loss: 0.6778 - acc: 0.6479\n",
      "Epoch 2/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.5151 - acc: 0.8998\n",
      "Epoch 3/100\n",
      "409/409 [==============================] - 0s 154us/step - loss: 0.2882 - acc: 0.9511\n",
      "Epoch 4/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.1775 - acc: 0.9658\n",
      "Epoch 5/100\n",
      "409/409 [==============================] - 0s 153us/step - loss: 0.1217 - acc: 0.9731\n",
      "Epoch 6/100\n",
      "409/409 [==============================] - 0s 155us/step - loss: 0.0976 - acc: 0.9756\n",
      "Epoch 7/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0852 - acc: 0.9829\n",
      "Epoch 8/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0772 - acc: 0.9853\n",
      "Epoch 9/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0727 - acc: 0.9853\n",
      "Epoch 10/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0688 - acc: 0.9878\n",
      "Epoch 11/100\n",
      "409/409 [==============================] - 0s 123us/step - loss: 0.0651 - acc: 0.9878\n",
      "Epoch 12/100\n",
      "409/409 [==============================] - 0s 131us/step - loss: 0.0625 - acc: 0.9878\n",
      "Epoch 13/100\n",
      "409/409 [==============================] - 0s 123us/step - loss: 0.0602 - acc: 0.9878\n",
      "Epoch 14/100\n",
      "409/409 [==============================] - 0s 133us/step - loss: 0.0582 - acc: 0.9878\n",
      "Epoch 15/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0563 - acc: 0.9878\n",
      "Epoch 16/100\n",
      "409/409 [==============================] - 0s 121us/step - loss: 0.0543 - acc: 0.9878\n",
      "Epoch 17/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0532 - acc: 0.9878\n",
      "Epoch 18/100\n",
      "409/409 [==============================] - 0s 149us/step - loss: 0.0508 - acc: 0.9878\n",
      "Epoch 19/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0496 - acc: 0.9878\n",
      "Epoch 20/100\n",
      "409/409 [==============================] - 0s 138us/step - loss: 0.0482 - acc: 0.9878\n",
      "Epoch 21/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0475 - acc: 0.9878\n",
      "Epoch 22/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0465 - acc: 0.9878\n",
      "Epoch 23/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0445 - acc: 0.9902\n",
      "Epoch 24/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0439 - acc: 0.9902\n",
      "Epoch 25/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0426 - acc: 0.9902\n",
      "Epoch 26/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.0416 - acc: 0.9902\n",
      "Epoch 27/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0406 - acc: 0.9902\n",
      "Epoch 28/100\n",
      "409/409 [==============================] - 0s 134us/step - loss: 0.0400 - acc: 0.9902\n",
      "Epoch 29/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0391 - acc: 0.9902\n",
      "Epoch 30/100\n",
      "409/409 [==============================] - 0s 153us/step - loss: 0.0380 - acc: 0.9902\n",
      "Epoch 31/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0373 - acc: 0.9902\n",
      "Epoch 32/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0367 - acc: 0.9902\n",
      "Epoch 33/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0361 - acc: 0.9902\n",
      "Epoch 34/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0351 - acc: 0.9902\n",
      "Epoch 35/100\n",
      "409/409 [==============================] - 0s 134us/step - loss: 0.0345 - acc: 0.9902\n",
      "Epoch 36/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0337 - acc: 0.9902\n",
      "Epoch 37/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0330 - acc: 0.9902\n",
      "Epoch 38/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0327 - acc: 0.9902\n",
      "Epoch 39/100\n",
      "409/409 [==============================] - 0s 136us/step - loss: 0.0321 - acc: 0.9902\n",
      "Epoch 40/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0313 - acc: 0.9902\n",
      "Epoch 41/100\n",
      "409/409 [==============================] - 0s 160us/step - loss: 0.0307 - acc: 0.9902\n",
      "Epoch 42/100\n",
      "409/409 [==============================] - 0s 168us/step - loss: 0.0300 - acc: 0.9902\n",
      "Epoch 43/100\n",
      "409/409 [==============================] - 0s 158us/step - loss: 0.0295 - acc: 0.9902\n",
      "Epoch 44/100\n",
      "409/409 [==============================] - 0s 159us/step - loss: 0.0297 - acc: 0.9902\n",
      "Epoch 45/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0284 - acc: 0.9902\n",
      "Epoch 46/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0271 - acc: 0.9902\n",
      "Epoch 47/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0258 - acc: 0.9927\n",
      "Epoch 48/100\n",
      "409/409 [==============================] - 0s 161us/step - loss: 0.0254 - acc: 0.9927\n",
      "Epoch 49/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0256 - acc: 0.9927\n",
      "Epoch 50/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0238 - acc: 0.9927\n",
      "Epoch 51/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0236 - acc: 0.9927\n",
      "Epoch 52/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0220 - acc: 0.9951\n",
      "Epoch 53/100\n",
      "409/409 [==============================] - 0s 133us/step - loss: 0.0206 - acc: 0.9951\n",
      "Epoch 54/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0204 - acc: 0.9951\n",
      "Epoch 55/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.0198 - acc: 0.9951\n",
      "Epoch 56/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0198 - acc: 0.9927\n",
      "Epoch 57/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0176 - acc: 0.9951\n",
      "Epoch 58/100\n",
      "409/409 [==============================] - 0s 122us/step - loss: 0.0176 - acc: 0.9951\n",
      "Epoch 59/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0167 - acc: 0.9951\n",
      "Epoch 60/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0162 - acc: 0.9951\n",
      "Epoch 61/100\n",
      "409/409 [==============================] - 0s 147us/step - loss: 0.0149 - acc: 0.9951\n",
      "Epoch 62/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0154 - acc: 0.9902\n",
      "Epoch 63/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0150 - acc: 0.9976\n",
      "Epoch 64/100\n",
      "409/409 [==============================] - 0s 167us/step - loss: 0.0121 - acc: 0.9951\n",
      "Epoch 65/100\n",
      "409/409 [==============================] - 0s 170us/step - loss: 0.0114 - acc: 0.9976\n",
      "Epoch 66/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0111 - acc: 0.9976\n",
      "Epoch 67/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0101 - acc: 0.9976\n",
      "Epoch 68/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0103 - acc: 0.9976\n",
      "Epoch 69/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0091 - acc: 0.9976\n",
      "Epoch 70/100\n",
      "409/409 [==============================] - 0s 152us/step - loss: 0.0091 - acc: 0.9976\n",
      "Epoch 71/100\n",
      "409/409 [==============================] - 0s 157us/step - loss: 0.0078 - acc: 0.9976\n",
      "Epoch 72/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0077 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0073 - acc: 0.9976\n",
      "Epoch 75/100\n",
      "409/409 [==============================] - 0s 171us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0062 - acc: 0.9976\n",
      "Epoch 77/100\n",
      "409/409 [==============================] - 0s 121us/step - loss: 0.0053 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "409/409 [==============================] - 0s 154us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "409/409 [==============================] - 0s 131us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "409/409 [==============================] - 0s 123us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "409/409 [==============================] - 0s 146us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "409/409 [==============================] - 0s 160us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "409/409 [==============================] - 0s 166us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "409/409 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "409/409 [==============================] - 0s 157us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "409/409 [==============================] - 0s 146us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "409/409 [==============================] - 0s 172us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "409/409 [==============================] - 0s 132us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "409/409 [==============================] - 0s 141us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 1/100\n",
      "409/409 [==============================] - 0s 859us/step - loss: 0.6815 - acc: 0.6944\n",
      "Epoch 2/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.5187 - acc: 0.9364\n",
      "Epoch 3/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.2562 - acc: 0.9535\n",
      "Epoch 4/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.1480 - acc: 0.9707\n",
      "Epoch 5/100\n",
      "409/409 [==============================] - 0s 132us/step - loss: 0.1120 - acc: 0.9707\n",
      "Epoch 6/100\n",
      "409/409 [==============================] - 0s 122us/step - loss: 0.0949 - acc: 0.9756\n",
      "Epoch 7/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0832 - acc: 0.9804\n",
      "Epoch 8/100\n",
      "409/409 [==============================] - 0s 160us/step - loss: 0.0762 - acc: 0.9829\n",
      "Epoch 9/100\n",
      "409/409 [==============================] - 0s 177us/step - loss: 0.0716 - acc: 0.9853\n",
      "Epoch 10/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0676 - acc: 0.9878\n",
      "Epoch 11/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0645 - acc: 0.9878\n",
      "Epoch 12/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0618 - acc: 0.9878\n",
      "Epoch 13/100\n",
      "409/409 [==============================] - 0s 135us/step - loss: 0.0598 - acc: 0.9878\n",
      "Epoch 14/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0567 - acc: 0.9878\n",
      "Epoch 15/100\n",
      "409/409 [==============================] - 0s 131us/step - loss: 0.0554 - acc: 0.9878\n",
      "Epoch 16/100\n",
      "409/409 [==============================] - 0s 138us/step - loss: 0.0533 - acc: 0.9878\n",
      "Epoch 17/100\n",
      "409/409 [==============================] - 0s 135us/step - loss: 0.0524 - acc: 0.9878\n",
      "Epoch 18/100\n",
      "409/409 [==============================] - 0s 141us/step - loss: 0.0506 - acc: 0.9878\n",
      "Epoch 19/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0497 - acc: 0.9878\n",
      "Epoch 20/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0484 - acc: 0.9878\n",
      "Epoch 21/100\n",
      "409/409 [==============================] - 0s 147us/step - loss: 0.0473 - acc: 0.9878\n",
      "Epoch 22/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0463 - acc: 0.9878\n",
      "Epoch 23/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0451 - acc: 0.9902\n",
      "Epoch 24/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0447 - acc: 0.9902\n",
      "Epoch 25/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0429 - acc: 0.9902\n",
      "Epoch 26/100\n",
      "409/409 [==============================] - 0s 141us/step - loss: 0.0425 - acc: 0.9902\n",
      "Epoch 27/100\n",
      "409/409 [==============================] - 0s 154us/step - loss: 0.0420 - acc: 0.9902\n",
      "Epoch 28/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0413 - acc: 0.9902\n",
      "Epoch 29/100\n",
      "409/409 [==============================] - 0s 136us/step - loss: 0.0398 - acc: 0.9902\n",
      "Epoch 30/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0386 - acc: 0.9902\n",
      "Epoch 31/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0383 - acc: 0.9902\n",
      "Epoch 32/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0373 - acc: 0.9902\n",
      "Epoch 33/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.0364 - acc: 0.9902\n",
      "Epoch 34/100\n",
      "409/409 [==============================] - 0s 135us/step - loss: 0.0351 - acc: 0.9902\n",
      "Epoch 35/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0347 - acc: 0.9902\n",
      "Epoch 36/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0343 - acc: 0.9902\n",
      "Epoch 37/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0334 - acc: 0.9902\n",
      "Epoch 38/100\n",
      "409/409 [==============================] - 0s 141us/step - loss: 0.0328 - acc: 0.9902\n",
      "Epoch 39/100\n",
      "409/409 [==============================] - 0s 131us/step - loss: 0.0318 - acc: 0.9902\n",
      "Epoch 40/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0313 - acc: 0.9902\n",
      "Epoch 41/100\n",
      "409/409 [==============================] - 0s 135us/step - loss: 0.0306 - acc: 0.9902\n",
      "Epoch 42/100\n",
      "409/409 [==============================] - 0s 135us/step - loss: 0.0301 - acc: 0.9902\n",
      "Epoch 43/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0296 - acc: 0.9902\n",
      "Epoch 44/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0291 - acc: 0.9902\n",
      "Epoch 45/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0284 - acc: 0.9902\n",
      "Epoch 46/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0275 - acc: 0.9902\n",
      "Epoch 47/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0266 - acc: 0.9902\n",
      "Epoch 48/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0258 - acc: 0.9902\n",
      "Epoch 49/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0250 - acc: 0.9927\n",
      "Epoch 50/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0236 - acc: 0.9927\n",
      "Epoch 51/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0225 - acc: 0.9927\n",
      "Epoch 52/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0217 - acc: 0.9927\n",
      "Epoch 53/100\n",
      "409/409 [==============================] - 0s 131us/step - loss: 0.0209 - acc: 0.9951\n",
      "Epoch 54/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0203 - acc: 0.9951\n",
      "Epoch 55/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0200 - acc: 0.9951\n",
      "Epoch 56/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0198 - acc: 0.9951\n",
      "Epoch 57/100\n",
      "409/409 [==============================] - 0s 157us/step - loss: 0.0190 - acc: 0.9951\n",
      "Epoch 58/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0186 - acc: 0.9951\n",
      "Epoch 59/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0183 - acc: 0.9951\n",
      "Epoch 60/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0177 - acc: 0.9951\n",
      "Epoch 61/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0186 - acc: 0.9951\n",
      "Epoch 62/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0177 - acc: 0.9951\n",
      "Epoch 63/100\n",
      "409/409 [==============================] - 0s 138us/step - loss: 0.0176 - acc: 0.9951\n",
      "Epoch 64/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0165 - acc: 0.9951\n",
      "Epoch 65/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0153 - acc: 0.9951\n",
      "Epoch 66/100\n",
      "409/409 [==============================] - 0s 134us/step - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 67/100\n",
      "409/409 [==============================] - 0s 146us/step - loss: 0.0135 - acc: 0.9951\n",
      "Epoch 68/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0125 - acc: 0.9951\n",
      "Epoch 69/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0116 - acc: 0.9976\n",
      "Epoch 70/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0099 - acc: 0.9951\n",
      "Epoch 71/100\n",
      "409/409 [==============================] - 0s 155us/step - loss: 0.0089 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0093 - acc: 0.9976\n",
      "Epoch 73/100\n",
      "409/409 [==============================] - 0s 173us/step - loss: 0.0080 - acc: 0.9976\n",
      "Epoch 74/100\n",
      "409/409 [==============================] - 0s 168us/step - loss: 0.0076 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "409/409 [==============================] - 0s 195us/step - loss: 0.0071 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "409/409 [==============================] - 0s 165us/step - loss: 0.0060 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0058 - acc: 0.9976\n",
      "Epoch 80/100\n",
      "409/409 [==============================] - 0s 166us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "409/409 [==============================] - 0s 172us/step - loss: 0.0251 - acc: 0.9902\n",
      "Epoch 82/100\n",
      "409/409 [==============================] - 0s 176us/step - loss: 0.0090 - acc: 0.9976\n",
      "Epoch 83/100\n",
      "409/409 [==============================] - 0s 165us/step - loss: 0.0052 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "409/409 [==============================] - 0s 168us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "409/409 [==============================] - 0s 166us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "409/409 [==============================] - 0s 155us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "409/409 [==============================] - 0s 179us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "409/409 [==============================] - 0s 163us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "409/409 [==============================] - 0s 165us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 1/100\n",
      "409/409 [==============================] - 0s 943us/step - loss: 0.6817 - acc: 0.8386\n",
      "Epoch 2/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.5571 - acc: 0.9462\n",
      "Epoch 3/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.2881 - acc: 0.9584\n",
      "Epoch 4/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.1540 - acc: 0.9731\n",
      "Epoch 5/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.1126 - acc: 0.9731\n",
      "Epoch 6/100\n",
      "409/409 [==============================] - 0s 131us/step - loss: 0.0951 - acc: 0.9731\n",
      "Epoch 7/100\n",
      "409/409 [==============================] - 0s 133us/step - loss: 0.0853 - acc: 0.9780\n",
      "Epoch 8/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0789 - acc: 0.9780\n",
      "Epoch 9/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0735 - acc: 0.9804\n",
      "Epoch 10/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0694 - acc: 0.9853\n",
      "Epoch 11/100\n",
      "409/409 [==============================] - 0s 157us/step - loss: 0.0667 - acc: 0.9878\n",
      "Epoch 12/100\n",
      "409/409 [==============================] - 0s 165us/step - loss: 0.0640 - acc: 0.9878\n",
      "Epoch 13/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0617 - acc: 0.9878\n",
      "Epoch 14/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0596 - acc: 0.9878\n",
      "Epoch 15/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0576 - acc: 0.9878\n",
      "Epoch 16/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0558 - acc: 0.9878\n",
      "Epoch 17/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0543 - acc: 0.9878\n",
      "Epoch 18/100\n",
      "409/409 [==============================] - 0s 122us/step - loss: 0.0526 - acc: 0.9878\n",
      "Epoch 19/100\n",
      "409/409 [==============================] - 0s 155us/step - loss: 0.0514 - acc: 0.9878\n",
      "Epoch 20/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0504 - acc: 0.9878\n",
      "Epoch 21/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0494 - acc: 0.9878\n",
      "Epoch 22/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0480 - acc: 0.9878\n",
      "Epoch 23/100\n",
      "409/409 [==============================] - 0s 159us/step - loss: 0.0477 - acc: 0.9902\n",
      "Epoch 24/100\n",
      "409/409 [==============================] - 0s 152us/step - loss: 0.0460 - acc: 0.9902\n",
      "Epoch 25/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0457 - acc: 0.9902\n",
      "Epoch 26/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0444 - acc: 0.9902\n",
      "Epoch 27/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0432 - acc: 0.9902\n",
      "Epoch 28/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0428 - acc: 0.9902\n",
      "Epoch 29/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0418 - acc: 0.9902\n",
      "Epoch 30/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0409 - acc: 0.9902\n",
      "Epoch 31/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0407 - acc: 0.9902\n",
      "Epoch 32/100\n",
      "409/409 [==============================] - 0s 147us/step - loss: 0.0402 - acc: 0.9902\n",
      "Epoch 33/100\n",
      "409/409 [==============================] - 0s 133us/step - loss: 0.0389 - acc: 0.9902\n",
      "Epoch 34/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.0380 - acc: 0.9902\n",
      "Epoch 35/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0375 - acc: 0.9902\n",
      "Epoch 36/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0368 - acc: 0.9902\n",
      "Epoch 37/100\n",
      "409/409 [==============================] - 0s 158us/step - loss: 0.0368 - acc: 0.9902\n",
      "Epoch 38/100\n",
      "409/409 [==============================] - 0s 162us/step - loss: 0.0359 - acc: 0.9902\n",
      "Epoch 39/100\n",
      "409/409 [==============================] - 0s 147us/step - loss: 0.0354 - acc: 0.9902\n",
      "Epoch 40/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0351 - acc: 0.9902\n",
      "Epoch 41/100\n",
      "409/409 [==============================] - 0s 153us/step - loss: 0.0340 - acc: 0.9902\n",
      "Epoch 42/100\n",
      "409/409 [==============================] - 0s 170us/step - loss: 0.0336 - acc: 0.9902\n",
      "Epoch 43/100\n",
      "409/409 [==============================] - 0s 162us/step - loss: 0.0328 - acc: 0.9902\n",
      "Epoch 44/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0323 - acc: 0.9902\n",
      "Epoch 45/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.0316 - acc: 0.9902\n",
      "Epoch 46/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0311 - acc: 0.9902\n",
      "Epoch 47/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0306 - acc: 0.9902\n",
      "Epoch 48/100\n",
      "409/409 [==============================] - 0s 153us/step - loss: 0.0298 - acc: 0.9902\n",
      "Epoch 49/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0294 - acc: 0.9902\n",
      "Epoch 50/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0290 - acc: 0.9902\n",
      "Epoch 51/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.0277 - acc: 0.9902\n",
      "Epoch 52/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0273 - acc: 0.9902\n",
      "Epoch 53/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.0273 - acc: 0.9902\n",
      "Epoch 54/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0264 - acc: 0.9902\n",
      "Epoch 55/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.0259 - acc: 0.9902\n",
      "Epoch 56/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0256 - acc: 0.9902\n",
      "Epoch 57/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0249 - acc: 0.9902\n",
      "Epoch 58/100\n",
      "409/409 [==============================] - 0s 131us/step - loss: 0.0240 - acc: 0.9902\n",
      "Epoch 59/100\n",
      "409/409 [==============================] - 0s 138us/step - loss: 0.0231 - acc: 0.9902\n",
      "Epoch 60/100\n",
      "409/409 [==============================] - 0s 149us/step - loss: 0.0225 - acc: 0.9902\n",
      "Epoch 61/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0215 - acc: 0.9902\n",
      "Epoch 62/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0212 - acc: 0.9902\n",
      "Epoch 63/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0206 - acc: 0.9902\n",
      "Epoch 64/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0197 - acc: 0.9927\n",
      "Epoch 65/100\n",
      "409/409 [==============================] - 0s 125us/step - loss: 0.0198 - acc: 0.9902\n",
      "Epoch 66/100\n",
      "409/409 [==============================] - 0s 141us/step - loss: 0.0194 - acc: 0.9927\n",
      "Epoch 67/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0191 - acc: 0.9902\n",
      "Epoch 68/100\n",
      "409/409 [==============================] - 0s 147us/step - loss: 0.0180 - acc: 0.9927\n",
      "Epoch 69/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0175 - acc: 0.9927\n",
      "Epoch 70/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0174 - acc: 0.9927\n",
      "Epoch 71/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0172 - acc: 0.9927\n",
      "Epoch 72/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0169 - acc: 0.9951\n",
      "Epoch 73/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0167 - acc: 0.9951\n",
      "Epoch 74/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0162 - acc: 0.9951\n",
      "Epoch 75/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0157 - acc: 0.9951\n",
      "Epoch 76/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0157 - acc: 0.9951\n",
      "Epoch 77/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0152 - acc: 0.9976\n",
      "Epoch 78/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0149 - acc: 0.9951\n",
      "Epoch 79/100\n",
      "409/409 [==============================] - 0s 147us/step - loss: 0.0144 - acc: 0.9976\n",
      "Epoch 80/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0140 - acc: 0.9976\n",
      "Epoch 81/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0140 - acc: 0.9951\n",
      "Epoch 82/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0136 - acc: 0.9976\n",
      "Epoch 83/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0129 - acc: 0.9976\n",
      "Epoch 84/100\n",
      "409/409 [==============================] - 0s 174us/step - loss: 0.0133 - acc: 0.9951\n",
      "Epoch 85/100\n",
      "409/409 [==============================] - 0s 172us/step - loss: 0.0127 - acc: 0.9976\n",
      "Epoch 86/100\n",
      "409/409 [==============================] - 0s 162us/step - loss: 0.0125 - acc: 0.9976\n",
      "Epoch 87/100\n",
      "409/409 [==============================] - 0s 161us/step - loss: 0.0119 - acc: 0.9976\n",
      "Epoch 88/100\n",
      "409/409 [==============================] - 0s 168us/step - loss: 0.0115 - acc: 0.9976\n",
      "Epoch 89/100\n",
      "409/409 [==============================] - 0s 134us/step - loss: 0.0113 - acc: 0.9976\n",
      "Epoch 90/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0107 - acc: 0.9951\n",
      "Epoch 91/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0100 - acc: 0.9976\n",
      "Epoch 92/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0094 - acc: 0.9976\n",
      "Epoch 93/100\n",
      "409/409 [==============================] - 0s 135us/step - loss: 0.0089 - acc: 0.9976\n",
      "Epoch 94/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0087 - acc: 0.9976\n",
      "Epoch 95/100\n",
      "409/409 [==============================] - 0s 146us/step - loss: 0.0080 - acc: 0.9976\n",
      "Epoch 96/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0080 - acc: 0.9976\n",
      "Epoch 97/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0073 - acc: 0.9976\n",
      "Epoch 98/100\n",
      "409/409 [==============================] - 0s 138us/step - loss: 0.0070 - acc: 0.9976\n",
      "Epoch 99/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0066 - acc: 0.9976\n",
      "Epoch 100/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 1/100\n",
      "409/409 [==============================] - 0s 1ms/step - loss: 0.6867 - acc: 0.7579\n",
      "Epoch 2/100\n",
      "409/409 [==============================] - 0s 124us/step - loss: 0.5642 - acc: 0.9511\n",
      "Epoch 3/100\n",
      "409/409 [==============================] - 0s 133us/step - loss: 0.2887 - acc: 0.9658\n",
      "Epoch 4/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.1381 - acc: 0.9756\n",
      "Epoch 5/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0943 - acc: 0.9756\n",
      "Epoch 6/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0776 - acc: 0.9804\n",
      "Epoch 7/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0686 - acc: 0.9829\n",
      "Epoch 8/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0632 - acc: 0.9853\n",
      "Epoch 9/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0593 - acc: 0.9878\n",
      "Epoch 10/100\n",
      "409/409 [==============================] - 0s 158us/step - loss: 0.0560 - acc: 0.9902\n",
      "Epoch 11/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0533 - acc: 0.9902\n",
      "Epoch 12/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0516 - acc: 0.9902\n",
      "Epoch 13/100\n",
      "409/409 [==============================] - 0s 157us/step - loss: 0.0500 - acc: 0.9902\n",
      "Epoch 14/100\n",
      "409/409 [==============================] - 0s 162us/step - loss: 0.0476 - acc: 0.9902\n",
      "Epoch 15/100\n",
      "409/409 [==============================] - 0s 160us/step - loss: 0.0459 - acc: 0.9902\n",
      "Epoch 16/100\n",
      "409/409 [==============================] - 0s 161us/step - loss: 0.0446 - acc: 0.9902\n",
      "Epoch 17/100\n",
      "409/409 [==============================] - 0s 167us/step - loss: 0.0431 - acc: 0.9902\n",
      "Epoch 18/100\n",
      "409/409 [==============================] - 0s 131us/step - loss: 0.0417 - acc: 0.9902\n",
      "Epoch 19/100\n",
      "409/409 [==============================] - 0s 146us/step - loss: 0.0410 - acc: 0.9902\n",
      "Epoch 20/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0397 - acc: 0.9902\n",
      "Epoch 21/100\n",
      "409/409 [==============================] - 0s 159us/step - loss: 0.0385 - acc: 0.9927\n",
      "Epoch 22/100\n",
      "409/409 [==============================] - 0s 133us/step - loss: 0.0377 - acc: 0.9927\n",
      "Epoch 23/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0366 - acc: 0.9927\n",
      "Epoch 24/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0358 - acc: 0.9927\n",
      "Epoch 25/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0347 - acc: 0.9927\n",
      "Epoch 26/100\n",
      "409/409 [==============================] - 0s 158us/step - loss: 0.0339 - acc: 0.9927\n",
      "Epoch 27/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0338 - acc: 0.9927\n",
      "Epoch 28/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0326 - acc: 0.9927\n",
      "Epoch 29/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0318 - acc: 0.9927\n",
      "Epoch 30/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0313 - acc: 0.9927\n",
      "Epoch 31/100\n",
      "409/409 [==============================] - 0s 149us/step - loss: 0.0307 - acc: 0.9927\n",
      "Epoch 32/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0299 - acc: 0.9927\n",
      "Epoch 33/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0296 - acc: 0.9927\n",
      "Epoch 34/100\n",
      "409/409 [==============================] - 0s 133us/step - loss: 0.0298 - acc: 0.9927\n",
      "Epoch 35/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0285 - acc: 0.9927\n",
      "Epoch 36/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0278 - acc: 0.9927\n",
      "Epoch 37/100\n",
      "409/409 [==============================] - 0s 172us/step - loss: 0.0270 - acc: 0.9927\n",
      "Epoch 38/100\n",
      "409/409 [==============================] - 0s 165us/step - loss: 0.0266 - acc: 0.9927\n",
      "Epoch 39/100\n",
      "409/409 [==============================] - 0s 191us/step - loss: 0.0261 - acc: 0.9927\n",
      "Epoch 40/100\n",
      "409/409 [==============================] - 0s 157us/step - loss: 0.0255 - acc: 0.9927\n",
      "Epoch 41/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0251 - acc: 0.9927\n",
      "Epoch 42/100\n",
      "409/409 [==============================] - 0s 141us/step - loss: 0.0246 - acc: 0.9927\n",
      "Epoch 43/100\n",
      "409/409 [==============================] - 0s 159us/step - loss: 0.0233 - acc: 0.9927\n",
      "Epoch 44/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0219 - acc: 0.9927\n",
      "Epoch 45/100\n",
      "409/409 [==============================] - 0s 155us/step - loss: 0.0211 - acc: 0.9927\n",
      "Epoch 46/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0202 - acc: 0.9951\n",
      "Epoch 47/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0195 - acc: 0.9951\n",
      "Epoch 48/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0187 - acc: 0.9951\n",
      "Epoch 49/100\n",
      "409/409 [==============================] - 0s 147us/step - loss: 0.0179 - acc: 0.9951\n",
      "Epoch 50/100\n",
      "409/409 [==============================] - 0s 167us/step - loss: 0.0174 - acc: 0.9951\n",
      "Epoch 51/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0169 - acc: 0.9951\n",
      "Epoch 52/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 53/100\n",
      "409/409 [==============================] - 0s 168us/step - loss: 0.0146 - acc: 0.9951\n",
      "Epoch 54/100\n",
      "409/409 [==============================] - 0s 167us/step - loss: 0.0138 - acc: 0.9951\n",
      "Epoch 55/100\n",
      "409/409 [==============================] - 0s 166us/step - loss: 0.0134 - acc: 0.9951\n",
      "Epoch 56/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0128 - acc: 0.9951\n",
      "Epoch 57/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0127 - acc: 0.9976\n",
      "Epoch 58/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0125 - acc: 0.9951\n",
      "Epoch 59/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0118 - acc: 0.9951\n",
      "Epoch 60/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0115 - acc: 0.9976\n",
      "Epoch 61/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0110 - acc: 0.9976\n",
      "Epoch 62/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0110 - acc: 0.9976\n",
      "Epoch 63/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0102 - acc: 0.9976\n",
      "Epoch 64/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0093 - acc: 0.9976\n",
      "Epoch 65/100\n",
      "409/409 [==============================] - 0s 131us/step - loss: 0.0087 - acc: 0.9976\n",
      "Epoch 66/100\n",
      "409/409 [==============================] - 0s 149us/step - loss: 0.0075 - acc: 0.9976\n",
      "Epoch 67/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0072 - acc: 0.9976\n",
      "Epoch 68/100\n",
      "409/409 [==============================] - 0s 149us/step - loss: 0.0064 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "409/409 [==============================] - 0s 165us/step - loss: 0.0065 - acc: 0.9976\n",
      "Epoch 70/100\n",
      "409/409 [==============================] - 0s 138us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0055 - acc: 0.9976\n",
      "Epoch 72/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0051 - acc: 0.9976\n",
      "Epoch 73/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "409/409 [==============================] - 0s 153us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "409/409 [==============================] - 0s 167us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "409/409 [==============================] - 0s 146us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "409/409 [==============================] - 0s 147us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "409/409 [==============================] - 0s 158us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "409/409 [==============================] - 0s 170us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "409/409 [==============================] - 0s 159us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "409/409 [==============================] - 0s 141us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "409/409 [==============================] - 0s 165us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "409/409 [==============================] - 0s 159us/step - loss: 0.0017 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "409/409 [==============================] - 0s 146us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "409/409 [==============================] - 0s 133us/step - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 1/100\n",
      "409/409 [==============================] - 0s 1ms/step - loss: 0.6813 - acc: 0.8362\n",
      "Epoch 2/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.5411 - acc: 0.9462\n",
      "Epoch 3/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.2636 - acc: 0.9584\n",
      "Epoch 4/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.1337 - acc: 0.9731\n",
      "Epoch 5/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0932 - acc: 0.9756\n",
      "Epoch 6/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0748 - acc: 0.9780\n",
      "Epoch 7/100\n",
      "409/409 [==============================] - 0s 132us/step - loss: 0.0638 - acc: 0.9829\n",
      "Epoch 8/100\n",
      "409/409 [==============================] - 0s 127us/step - loss: 0.0572 - acc: 0.9804\n",
      "Epoch 9/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0525 - acc: 0.9853\n",
      "Epoch 10/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0487 - acc: 0.9927\n",
      "Epoch 11/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0455 - acc: 0.9927\n",
      "Epoch 12/100\n",
      "409/409 [==============================] - 0s 165us/step - loss: 0.0433 - acc: 0.9902\n",
      "Epoch 13/100\n",
      "409/409 [==============================] - 0s 161us/step - loss: 0.0407 - acc: 0.9927\n",
      "Epoch 14/100\n",
      "409/409 [==============================] - 0s 146us/step - loss: 0.0385 - acc: 0.9927\n",
      "Epoch 15/100\n",
      "409/409 [==============================] - 0s 170us/step - loss: 0.0370 - acc: 0.9927\n",
      "Epoch 16/100\n",
      "409/409 [==============================] - 0s 159us/step - loss: 0.0356 - acc: 0.9927\n",
      "Epoch 17/100\n",
      "409/409 [==============================] - 0s 138us/step - loss: 0.0344 - acc: 0.9927\n",
      "Epoch 18/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0333 - acc: 0.9927\n",
      "Epoch 19/100\n",
      "409/409 [==============================] - 0s 132us/step - loss: 0.0321 - acc: 0.9927\n",
      "Epoch 20/100\n",
      "409/409 [==============================] - 0s 136us/step - loss: 0.0311 - acc: 0.9927\n",
      "Epoch 21/100\n",
      "409/409 [==============================] - 0s 165us/step - loss: 0.0301 - acc: 0.9927\n",
      "Epoch 22/100\n",
      "409/409 [==============================] - 0s 173us/step - loss: 0.0292 - acc: 0.9927\n",
      "Epoch 23/100\n",
      "409/409 [==============================] - 0s 172us/step - loss: 0.0284 - acc: 0.9927\n",
      "Epoch 24/100\n",
      "409/409 [==============================] - 0s 147us/step - loss: 0.0276 - acc: 0.9927\n",
      "Epoch 25/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0266 - acc: 0.9927\n",
      "Epoch 26/100\n",
      "409/409 [==============================] - 0s 138us/step - loss: 0.0259 - acc: 0.9951\n",
      "Epoch 27/100\n",
      "409/409 [==============================] - 0s 154us/step - loss: 0.0255 - acc: 0.9951\n",
      "Epoch 28/100\n",
      "409/409 [==============================] - 0s 155us/step - loss: 0.0248 - acc: 0.9951\n",
      "Epoch 29/100\n",
      "409/409 [==============================] - 0s 167us/step - loss: 0.0239 - acc: 0.9951\n",
      "Epoch 30/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0233 - acc: 0.9951\n",
      "Epoch 31/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0225 - acc: 0.9951\n",
      "Epoch 32/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0220 - acc: 0.9951\n",
      "Epoch 33/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0213 - acc: 0.9951\n",
      "Epoch 34/100\n",
      "409/409 [==============================] - 0s 149us/step - loss: 0.0209 - acc: 0.9951\n",
      "Epoch 35/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0206 - acc: 0.9951\n",
      "Epoch 36/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0198 - acc: 0.9951\n",
      "Epoch 37/100\n",
      "409/409 [==============================] - 0s 126us/step - loss: 0.0193 - acc: 0.9951\n",
      "Epoch 38/100\n",
      "409/409 [==============================] - 0s 154us/step - loss: 0.0189 - acc: 0.9951\n",
      "Epoch 39/100\n",
      "409/409 [==============================] - 0s 134us/step - loss: 0.0183 - acc: 0.9951\n",
      "Epoch 40/100\n",
      "409/409 [==============================] - 0s 129us/step - loss: 0.0179 - acc: 0.9951\n",
      "Epoch 41/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0176 - acc: 0.9951\n",
      "Epoch 42/100\n",
      "409/409 [==============================] - 0s 160us/step - loss: 0.0166 - acc: 0.9951\n",
      "Epoch 43/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0166 - acc: 0.9951\n",
      "Epoch 44/100\n",
      "409/409 [==============================] - 0s 150us/step - loss: 0.0160 - acc: 0.9951\n",
      "Epoch 45/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0157 - acc: 0.9951\n",
      "Epoch 46/100\n",
      "409/409 [==============================] - 0s 153us/step - loss: 0.0150 - acc: 0.9951\n",
      "Epoch 47/100\n",
      "409/409 [==============================] - 0s 135us/step - loss: 0.0147 - acc: 0.9951\n",
      "Epoch 48/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0140 - acc: 0.9951\n",
      "Epoch 49/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0135 - acc: 0.9951\n",
      "Epoch 50/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0129 - acc: 0.9951\n",
      "Epoch 51/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0125 - acc: 0.9951\n",
      "Epoch 52/100\n",
      "409/409 [==============================] - 0s 167us/step - loss: 0.0119 - acc: 0.9951\n",
      "Epoch 53/100\n",
      "409/409 [==============================] - 0s 179us/step - loss: 0.0117 - acc: 0.9951\n",
      "Epoch 54/100\n",
      "409/409 [==============================] - 0s 158us/step - loss: 0.0116 - acc: 0.9951\n",
      "Epoch 55/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0112 - acc: 0.9951\n",
      "Epoch 56/100\n",
      "409/409 [==============================] - 0s 149us/step - loss: 0.0108 - acc: 0.9951\n",
      "Epoch 57/100\n",
      "409/409 [==============================] - 0s 152us/step - loss: 0.0104 - acc: 0.9951\n",
      "Epoch 58/100\n",
      "409/409 [==============================] - 0s 185us/step - loss: 0.0102 - acc: 0.9951\n",
      "Epoch 59/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0099 - acc: 0.9951\n",
      "Epoch 60/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0098 - acc: 0.9951\n",
      "Epoch 61/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0096 - acc: 0.9976\n",
      "Epoch 62/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0092 - acc: 0.9976\n",
      "Epoch 63/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0086 - acc: 0.9976\n",
      "Epoch 64/100\n",
      "409/409 [==============================] - 0s 133us/step - loss: 0.0075 - acc: 0.9976\n",
      "Epoch 65/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0077 - acc: 0.9951\n",
      "Epoch 66/100\n",
      "409/409 [==============================] - 0s 152us/step - loss: 0.0070 - acc: 0.9976\n",
      "Epoch 67/100\n",
      "409/409 [==============================] - 0s 144us/step - loss: 0.0065 - acc: 0.9976\n",
      "Epoch 68/100\n",
      "409/409 [==============================] - 0s 149us/step - loss: 0.0060 - acc: 0.9976\n",
      "Epoch 69/100\n",
      "409/409 [==============================] - 0s 142us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "409/409 [==============================] - 0s 154us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "409/409 [==============================] - 0s 143us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "409/409 [==============================] - 0s 151us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "409/409 [==============================] - 0s 141us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "409/409 [==============================] - 0s 139us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "409/409 [==============================] - 0s 130us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "409/409 [==============================] - 0s 146us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "409/409 [==============================] - 0s 134us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "409/409 [==============================] - 0s 135us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "409/409 [==============================] - 0s 147us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "409/409 [==============================] - 0s 149us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "409/409 [==============================] - 0s 157us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "409/409 [==============================] - 0s 169us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "409/409 [==============================] - 0s 171us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "409/409 [==============================] - 0s 164us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "409/409 [==============================] - 0s 155us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "409/409 [==============================] - 0s 166us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "409/409 [==============================] - 0s 140us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "409/409 [==============================] - 0s 145us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "409/409 [==============================] - 0s 163us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "409/409 [==============================] - 0s 155us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "409/409 [==============================] - 0s 137us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "409/409 [==============================] - 0s 148us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "409/409 [==============================] - 0s 141us/step - loss: 0.0015 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "409/409 [==============================] - 0s 146us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "409/409 [==============================] - 0s 128us/step - loss: 0.0014 - acc: 1.0000\n",
      "Epoch 1/100\n",
      "410/410 [==============================] - 1s 1ms/step - loss: 0.6780 - acc: 0.6561\n",
      "Epoch 2/100\n",
      "410/410 [==============================] - 0s 124us/step - loss: 0.5215 - acc: 0.9000\n",
      "Epoch 3/100\n",
      "410/410 [==============================] - 0s 127us/step - loss: 0.2728 - acc: 0.9463\n",
      "Epoch 4/100\n",
      "410/410 [==============================] - 0s 125us/step - loss: 0.1548 - acc: 0.9659\n",
      "Epoch 5/100\n",
      "410/410 [==============================] - 0s 126us/step - loss: 0.1103 - acc: 0.9707\n",
      "Epoch 6/100\n",
      "410/410 [==============================] - 0s 126us/step - loss: 0.0874 - acc: 0.9756\n",
      "Epoch 7/100\n",
      "410/410 [==============================] - 0s 128us/step - loss: 0.0757 - acc: 0.9805\n",
      "Epoch 8/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0672 - acc: 0.9854\n",
      "Epoch 9/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0627 - acc: 0.9878\n",
      "Epoch 10/100\n",
      "410/410 [==============================] - 0s 127us/step - loss: 0.0580 - acc: 0.9902\n",
      "Epoch 11/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0548 - acc: 0.9902\n",
      "Epoch 12/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0538 - acc: 0.9902\n",
      "Epoch 13/100\n",
      "410/410 [==============================] - 0s 170us/step - loss: 0.0507 - acc: 0.9902\n",
      "Epoch 14/100\n",
      "410/410 [==============================] - 0s 166us/step - loss: 0.0489 - acc: 0.9902\n",
      "Epoch 15/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0475 - acc: 0.9902\n",
      "Epoch 16/100\n",
      "410/410 [==============================] - 0s 141us/step - loss: 0.0456 - acc: 0.9902\n",
      "Epoch 17/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0442 - acc: 0.9902\n",
      "Epoch 18/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0428 - acc: 0.9902\n",
      "Epoch 19/100\n",
      "410/410 [==============================] - 0s 139us/step - loss: 0.0414 - acc: 0.9902\n",
      "Epoch 20/100\n",
      "410/410 [==============================] - 0s 130us/step - loss: 0.0408 - acc: 0.9902\n",
      "Epoch 21/100\n",
      "410/410 [==============================] - 0s 137us/step - loss: 0.0395 - acc: 0.9902\n",
      "Epoch 22/100\n",
      "410/410 [==============================] - 0s 138us/step - loss: 0.0378 - acc: 0.9902\n",
      "Epoch 23/100\n",
      "410/410 [==============================] - 0s 138us/step - loss: 0.0373 - acc: 0.9927\n",
      "Epoch 24/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.0360 - acc: 0.9927\n",
      "Epoch 25/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0349 - acc: 0.9927\n",
      "Epoch 26/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0342 - acc: 0.9927\n",
      "Epoch 27/100\n",
      "410/410 [==============================] - 0s 129us/step - loss: 0.0336 - acc: 0.9927\n",
      "Epoch 28/100\n",
      "410/410 [==============================] - 0s 149us/step - loss: 0.0325 - acc: 0.9927\n",
      "Epoch 29/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0311 - acc: 0.9927\n",
      "Epoch 30/100\n",
      "410/410 [==============================] - 0s 127us/step - loss: 0.0304 - acc: 0.9927\n",
      "Epoch 31/100\n",
      "410/410 [==============================] - 0s 140us/step - loss: 0.0299 - acc: 0.9927\n",
      "Epoch 32/100\n",
      "410/410 [==============================] - 0s 128us/step - loss: 0.0284 - acc: 0.9927\n",
      "Epoch 33/100\n",
      "410/410 [==============================] - 0s 137us/step - loss: 0.0279 - acc: 0.9927\n",
      "Epoch 34/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0272 - acc: 0.9927\n",
      "Epoch 35/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0257 - acc: 0.9927\n",
      "Epoch 36/100\n",
      "410/410 [==============================] - 0s 137us/step - loss: 0.0252 - acc: 0.9927\n",
      "Epoch 37/100\n",
      "410/410 [==============================] - 0s 137us/step - loss: 0.0251 - acc: 0.9927\n",
      "Epoch 38/100\n",
      "410/410 [==============================] - 0s 129us/step - loss: 0.0242 - acc: 0.9927\n",
      "Epoch 39/100\n",
      "410/410 [==============================] - 0s 127us/step - loss: 0.0231 - acc: 0.9927\n",
      "Epoch 40/100\n",
      "410/410 [==============================] - 0s 135us/step - loss: 0.0219 - acc: 0.9927\n",
      "Epoch 41/100\n",
      "410/410 [==============================] - 0s 128us/step - loss: 0.0216 - acc: 0.9927\n",
      "Epoch 42/100\n",
      "410/410 [==============================] - 0s 141us/step - loss: 0.0213 - acc: 0.9927\n",
      "Epoch 43/100\n",
      "410/410 [==============================] - 0s 139us/step - loss: 0.0202 - acc: 0.9951\n",
      "Epoch 44/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0198 - acc: 0.9951\n",
      "Epoch 45/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0189 - acc: 0.9951\n",
      "Epoch 46/100\n",
      "410/410 [==============================] - 0s 139us/step - loss: 0.0182 - acc: 0.9951\n",
      "Epoch 47/100\n",
      "410/410 [==============================] - 0s 129us/step - loss: 0.0179 - acc: 0.9976\n",
      "Epoch 48/100\n",
      "410/410 [==============================] - 0s 133us/step - loss: 0.0175 - acc: 0.9951\n",
      "Epoch 49/100\n",
      "410/410 [==============================] - 0s 127us/step - loss: 0.0168 - acc: 0.9951\n",
      "Epoch 50/100\n",
      "410/410 [==============================] - 0s 127us/step - loss: 0.0167 - acc: 0.9976\n",
      "Epoch 51/100\n",
      "410/410 [==============================] - 0s 160us/step - loss: 0.0160 - acc: 0.9951\n",
      "Epoch 52/100\n",
      "410/410 [==============================] - 0s 169us/step - loss: 0.0155 - acc: 0.9951\n",
      "Epoch 53/100\n",
      "410/410 [==============================] - 0s 131us/step - loss: 0.0147 - acc: 0.9976\n",
      "Epoch 54/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0142 - acc: 0.9976\n",
      "Epoch 55/100\n",
      "410/410 [==============================] - 0s 141us/step - loss: 0.0138 - acc: 0.9976\n",
      "Epoch 56/100\n",
      "410/410 [==============================] - 0s 166us/step - loss: 0.0131 - acc: 0.9976\n",
      "Epoch 57/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0122 - acc: 0.9976\n",
      "Epoch 58/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0121 - acc: 0.9976\n",
      "Epoch 59/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0116 - acc: 0.9976\n",
      "Epoch 60/100\n",
      "410/410 [==============================] - 0s 141us/step - loss: 0.0118 - acc: 0.9976\n",
      "Epoch 61/100\n",
      "410/410 [==============================] - 0s 132us/step - loss: 0.0100 - acc: 0.9976\n",
      "Epoch 62/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0096 - acc: 0.9976\n",
      "Epoch 63/100\n",
      "410/410 [==============================] - 0s 138us/step - loss: 0.0093 - acc: 0.9976\n",
      "Epoch 64/100\n",
      "410/410 [==============================] - 0s 131us/step - loss: 0.0090 - acc: 0.9976\n",
      "Epoch 65/100\n",
      "410/410 [==============================] - 0s 144us/step - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 66/100\n",
      "410/410 [==============================] - 0s 144us/step - loss: 0.0077 - acc: 0.9976\n",
      "Epoch 67/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0078 - acc: 0.9976\n",
      "Epoch 68/100\n",
      "410/410 [==============================] - 0s 129us/step - loss: 0.0069 - acc: 0.9976\n",
      "Epoch 69/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0069 - acc: 0.9976\n",
      "Epoch 70/100\n",
      "410/410 [==============================] - 0s 162us/step - loss: 0.0065 - acc: 0.9976\n",
      "Epoch 71/100\n",
      "410/410 [==============================] - 0s 179us/step - loss: 0.0059 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "410/410 [==============================] - 0s 170us/step - loss: 0.0058 - acc: 0.9976\n",
      "Epoch 73/100\n",
      "410/410 [==============================] - 0s 166us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "410/410 [==============================] - 0s 158us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "410/410 [==============================] - 0s 129us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "410/410 [==============================] - 0s 140us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "410/410 [==============================] - 0s 135us/step - loss: 0.0035 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "410/410 [==============================] - 0s 129us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "410/410 [==============================] - 0s 142us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "410/410 [==============================] - 0s 140us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "410/410 [==============================] - 0s 132us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "410/410 [==============================] - 0s 149us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "410/410 [==============================] - 0s 135us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "410/410 [==============================] - 0s 136us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "410/410 [==============================] - 0s 144us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0022 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0020 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0019 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0018 - acc: 1.0000\n",
      "Epoch 1/100\n",
      "410/410 [==============================] - 1s 1ms/step - loss: 0.6805 - acc: 0.8098\n",
      "Epoch 2/100\n",
      "410/410 [==============================] - 0s 134us/step - loss: 0.5427 - acc: 0.9317\n",
      "Epoch 3/100\n",
      "410/410 [==============================] - 0s 122us/step - loss: 0.2568 - acc: 0.9488\n",
      "Epoch 4/100\n",
      "410/410 [==============================] - 0s 124us/step - loss: 0.1413 - acc: 0.9659\n",
      "Epoch 5/100\n",
      "410/410 [==============================] - 0s 126us/step - loss: 0.1038 - acc: 0.9732\n",
      "Epoch 6/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0880 - acc: 0.9780\n",
      "Epoch 7/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0781 - acc: 0.9805\n",
      "Epoch 8/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0723 - acc: 0.9805\n",
      "Epoch 9/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0676 - acc: 0.9878\n",
      "Epoch 10/100\n",
      "410/410 [==============================] - 0s 183us/step - loss: 0.0636 - acc: 0.9878\n",
      "Epoch 11/100\n",
      "410/410 [==============================] - 0s 135us/step - loss: 0.0611 - acc: 0.9878\n",
      "Epoch 12/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0583 - acc: 0.9878\n",
      "Epoch 13/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0568 - acc: 0.9878\n",
      "Epoch 14/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0549 - acc: 0.9878\n",
      "Epoch 15/100\n",
      "410/410 [==============================] - 0s 134us/step - loss: 0.0532 - acc: 0.9878\n",
      "Epoch 16/100\n",
      "410/410 [==============================] - 0s 140us/step - loss: 0.0514 - acc: 0.9878\n",
      "Epoch 17/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0501 - acc: 0.9878\n",
      "Epoch 18/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0491 - acc: 0.9878\n",
      "Epoch 19/100\n",
      "410/410 [==============================] - 0s 137us/step - loss: 0.0476 - acc: 0.9878\n",
      "Epoch 20/100\n",
      "410/410 [==============================] - 0s 138us/step - loss: 0.0461 - acc: 0.9902\n",
      "Epoch 21/100\n",
      "410/410 [==============================] - 0s 149us/step - loss: 0.0459 - acc: 0.9902\n",
      "Epoch 22/100\n",
      "410/410 [==============================] - 0s 130us/step - loss: 0.0444 - acc: 0.9902\n",
      "Epoch 23/100\n",
      "410/410 [==============================] - 0s 144us/step - loss: 0.0445 - acc: 0.9902\n",
      "Epoch 24/100\n",
      "410/410 [==============================] - 0s 130us/step - loss: 0.0426 - acc: 0.9902\n",
      "Epoch 25/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0415 - acc: 0.9902\n",
      "Epoch 26/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0408 - acc: 0.9902\n",
      "Epoch 27/100\n",
      "410/410 [==============================] - 0s 127us/step - loss: 0.0399 - acc: 0.9902\n",
      "Epoch 28/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0388 - acc: 0.9902\n",
      "Epoch 29/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0382 - acc: 0.9902\n",
      "Epoch 30/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0378 - acc: 0.9902\n",
      "Epoch 31/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0375 - acc: 0.9902\n",
      "Epoch 32/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0358 - acc: 0.9902\n",
      "Epoch 33/100\n",
      "410/410 [==============================] - 0s 135us/step - loss: 0.0349 - acc: 0.9902\n",
      "Epoch 34/100\n",
      "410/410 [==============================] - 0s 140us/step - loss: 0.0343 - acc: 0.9902\n",
      "Epoch 35/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0335 - acc: 0.9902\n",
      "Epoch 36/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0329 - acc: 0.9902\n",
      "Epoch 37/100\n",
      "410/410 [==============================] - 0s 168us/step - loss: 0.0329 - acc: 0.9902\n",
      "Epoch 38/100\n",
      "410/410 [==============================] - 0s 176us/step - loss: 0.0312 - acc: 0.9902\n",
      "Epoch 39/100\n",
      "410/410 [==============================] - 0s 176us/step - loss: 0.0306 - acc: 0.9902\n",
      "Epoch 40/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0297 - acc: 0.9902\n",
      "Epoch 41/100\n",
      "410/410 [==============================] - 0s 137us/step - loss: 0.0289 - acc: 0.9902\n",
      "Epoch 42/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0280 - acc: 0.9902\n",
      "Epoch 43/100\n",
      "410/410 [==============================] - 0s 160us/step - loss: 0.0275 - acc: 0.9902\n",
      "Epoch 44/100\n",
      "410/410 [==============================] - 0s 133us/step - loss: 0.0269 - acc: 0.9902\n",
      "Epoch 45/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0262 - acc: 0.9902\n",
      "Epoch 46/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0262 - acc: 0.9902\n",
      "Epoch 47/100\n",
      "410/410 [==============================] - 0s 138us/step - loss: 0.0248 - acc: 0.9902\n",
      "Epoch 48/100\n",
      "410/410 [==============================] - 0s 127us/step - loss: 0.0243 - acc: 0.9902\n",
      "Epoch 49/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0240 - acc: 0.9902\n",
      "Epoch 50/100\n",
      "410/410 [==============================] - 0s 142us/step - loss: 0.0234 - acc: 0.9902\n",
      "Epoch 51/100\n",
      "410/410 [==============================] - 0s 144us/step - loss: 0.0226 - acc: 0.9902\n",
      "Epoch 52/100\n",
      "410/410 [==============================] - 0s 162us/step - loss: 0.0218 - acc: 0.9902\n",
      "Epoch 53/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0217 - acc: 0.9902\n",
      "Epoch 54/100\n",
      "410/410 [==============================] - 0s 158us/step - loss: 0.0208 - acc: 0.9902\n",
      "Epoch 55/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0201 - acc: 0.9902\n",
      "Epoch 56/100\n",
      "410/410 [==============================] - 0s 139us/step - loss: 0.0200 - acc: 0.9927\n",
      "Epoch 57/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.0188 - acc: 0.9927\n",
      "Epoch 58/100\n",
      "410/410 [==============================] - 0s 129us/step - loss: 0.0183 - acc: 0.9927\n",
      "Epoch 59/100\n",
      "410/410 [==============================] - 0s 149us/step - loss: 0.0175 - acc: 0.9902\n",
      "Epoch 60/100\n",
      "410/410 [==============================] - 0s 141us/step - loss: 0.0161 - acc: 0.9902\n",
      "Epoch 61/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0158 - acc: 0.9927\n",
      "Epoch 62/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0146 - acc: 0.9951\n",
      "Epoch 63/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0141 - acc: 0.9927\n",
      "Epoch 64/100\n",
      "410/410 [==============================] - 0s 141us/step - loss: 0.0137 - acc: 0.9951\n",
      "Epoch 65/100\n",
      "410/410 [==============================] - 0s 141us/step - loss: 0.0130 - acc: 0.9927\n",
      "Epoch 66/100\n",
      "410/410 [==============================] - 0s 135us/step - loss: 0.0126 - acc: 0.9951\n",
      "Epoch 67/100\n",
      "410/410 [==============================] - 0s 128us/step - loss: 0.0118 - acc: 0.9976\n",
      "Epoch 68/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0118 - acc: 0.9976\n",
      "Epoch 69/100\n",
      "410/410 [==============================] - 0s 128us/step - loss: 0.0108 - acc: 0.9976\n",
      "Epoch 70/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0107 - acc: 0.9976\n",
      "Epoch 71/100\n",
      "410/410 [==============================] - 0s 141us/step - loss: 0.0095 - acc: 0.9976\n",
      "Epoch 72/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0088 - acc: 0.9976\n",
      "Epoch 73/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0088 - acc: 0.9976\n",
      "Epoch 74/100\n",
      "410/410 [==============================] - 0s 133us/step - loss: 0.0080 - acc: 0.9976\n",
      "Epoch 75/100\n",
      "410/410 [==============================] - 0s 167us/step - loss: 0.0074 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "410/410 [==============================] - 0s 137us/step - loss: 0.0076 - acc: 0.9976\n",
      "Epoch 77/100\n",
      "410/410 [==============================] - 0s 129us/step - loss: 0.0072 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0068 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "410/410 [==============================] - 0s 140us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "410/410 [==============================] - 0s 174us/step - loss: 0.0062 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "410/410 [==============================] - 0s 177us/step - loss: 0.0056 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "410/410 [==============================] - 0s 166us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0049 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0046 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "410/410 [==============================] - 0s 170us/step - loss: 0.0043 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "410/410 [==============================] - 0s 169us/step - loss: 0.0039 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "410/410 [==============================] - 0s 164us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "410/410 [==============================] - 0s 157us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "410/410 [==============================] - 0s 140us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "410/410 [==============================] - 0s 135us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "410/410 [==============================] - 0s 149us/step - loss: 0.0033 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "410/410 [==============================] - 0s 129us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0031 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0029 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "410/410 [==============================] - 0s 176us/step - loss: 0.0027 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "410/410 [==============================] - 0s 167us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "410/410 [==============================] - 0s 167us/step - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "410/410 [==============================] - 0s 139us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "410/410 [==============================] - 0s 138us/step - loss: 0.0021 - acc: 1.0000\n",
      "Epoch 1/100\n",
      "410/410 [==============================] - 1s 2ms/step - loss: 0.6793 - acc: 0.8463\n",
      "Epoch 2/100\n",
      "410/410 [==============================] - 0s 132us/step - loss: 0.5109 - acc: 0.9390\n",
      "Epoch 3/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.2314 - acc: 0.9488\n",
      "Epoch 4/100\n",
      "410/410 [==============================] - 0s 131us/step - loss: 0.1306 - acc: 0.9683\n",
      "Epoch 5/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.1000 - acc: 0.9756\n",
      "Epoch 6/100\n",
      "410/410 [==============================] - 0s 144us/step - loss: 0.0846 - acc: 0.9829\n",
      "Epoch 7/100\n",
      "410/410 [==============================] - 0s 157us/step - loss: 0.0763 - acc: 0.9805\n",
      "Epoch 8/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0709 - acc: 0.9878\n",
      "Epoch 9/100\n",
      "410/410 [==============================] - 0s 171us/step - loss: 0.0674 - acc: 0.9878\n",
      "Epoch 10/100\n",
      "410/410 [==============================] - 0s 167us/step - loss: 0.0646 - acc: 0.9878\n",
      "Epoch 11/100\n",
      "410/410 [==============================] - 0s 168us/step - loss: 0.0621 - acc: 0.9878\n",
      "Epoch 12/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0601 - acc: 0.9878\n",
      "Epoch 13/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0584 - acc: 0.9878\n",
      "Epoch 14/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0561 - acc: 0.9878\n",
      "Epoch 15/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0547 - acc: 0.9878\n",
      "Epoch 16/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0528 - acc: 0.9878\n",
      "Epoch 17/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.0526 - acc: 0.9878\n",
      "Epoch 18/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0501 - acc: 0.9878\n",
      "Epoch 19/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0490 - acc: 0.9878\n",
      "Epoch 20/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.0479 - acc: 0.9878\n",
      "Epoch 21/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0475 - acc: 0.9878\n",
      "Epoch 22/100\n",
      "410/410 [==============================] - 0s 149us/step - loss: 0.0456 - acc: 0.9902\n",
      "Epoch 23/100\n",
      "410/410 [==============================] - 0s 164us/step - loss: 0.0448 - acc: 0.9902\n",
      "Epoch 24/100\n",
      "410/410 [==============================] - 0s 175us/step - loss: 0.0436 - acc: 0.9902\n",
      "Epoch 25/100\n",
      "410/410 [==============================] - 0s 171us/step - loss: 0.0423 - acc: 0.9902\n",
      "Epoch 26/100\n",
      "410/410 [==============================] - 0s 177us/step - loss: 0.0415 - acc: 0.9902\n",
      "Epoch 27/100\n",
      "410/410 [==============================] - 0s 168us/step - loss: 0.0407 - acc: 0.9902\n",
      "Epoch 28/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0401 - acc: 0.9902\n",
      "Epoch 29/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0390 - acc: 0.9902\n",
      "Epoch 30/100\n",
      "410/410 [==============================] - 0s 169us/step - loss: 0.0379 - acc: 0.9902\n",
      "Epoch 31/100\n",
      "410/410 [==============================] - 0s 166us/step - loss: 0.0372 - acc: 0.9902\n",
      "Epoch 32/100\n",
      "410/410 [==============================] - 0s 171us/step - loss: 0.0364 - acc: 0.9902\n",
      "Epoch 33/100\n",
      "410/410 [==============================] - 0s 149us/step - loss: 0.0355 - acc: 0.9902\n",
      "Epoch 34/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0348 - acc: 0.9902\n",
      "Epoch 35/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0337 - acc: 0.9902\n",
      "Epoch 36/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0329 - acc: 0.9902\n",
      "Epoch 37/100\n",
      "410/410 [==============================] - 0s 134us/step - loss: 0.0330 - acc: 0.9902\n",
      "Epoch 38/100\n",
      "410/410 [==============================] - 0s 138us/step - loss: 0.0314 - acc: 0.9902\n",
      "Epoch 39/100\n",
      "410/410 [==============================] - 0s 138us/step - loss: 0.0308 - acc: 0.9902\n",
      "Epoch 40/100\n",
      "410/410 [==============================] - 0s 168us/step - loss: 0.0299 - acc: 0.9902\n",
      "Epoch 41/100\n",
      "410/410 [==============================] - 0s 180us/step - loss: 0.0288 - acc: 0.9902\n",
      "Epoch 42/100\n",
      "410/410 [==============================] - 0s 175us/step - loss: 0.0284 - acc: 0.9902\n",
      "Epoch 43/100\n",
      "410/410 [==============================] - 0s 162us/step - loss: 0.0275 - acc: 0.9902\n",
      "Epoch 44/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0263 - acc: 0.9902\n",
      "Epoch 45/100\n",
      "410/410 [==============================] - 0s 156us/step - loss: 0.0252 - acc: 0.9902\n",
      "Epoch 46/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0247 - acc: 0.9927\n",
      "Epoch 47/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0246 - acc: 0.9902\n",
      "Epoch 48/100\n",
      "410/410 [==============================] - 0s 160us/step - loss: 0.0232 - acc: 0.9927\n",
      "Epoch 49/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0222 - acc: 0.9927\n",
      "Epoch 50/100\n",
      "410/410 [==============================] - 0s 139us/step - loss: 0.0218 - acc: 0.9927\n",
      "Epoch 51/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0219 - acc: 0.9927\n",
      "Epoch 52/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0211 - acc: 0.9902\n",
      "Epoch 53/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0202 - acc: 0.9927\n",
      "Epoch 54/100\n",
      "410/410 [==============================] - 0s 162us/step - loss: 0.0198 - acc: 0.9927\n",
      "Epoch 55/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0191 - acc: 0.9951\n",
      "Epoch 56/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0193 - acc: 0.9927\n",
      "Epoch 57/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0178 - acc: 0.9951\n",
      "Epoch 58/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0174 - acc: 0.9951\n",
      "Epoch 59/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0177 - acc: 0.9927\n",
      "Epoch 60/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0164 - acc: 0.9951\n",
      "Epoch 61/100\n",
      "410/410 [==============================] - 0s 175us/step - loss: 0.0163 - acc: 0.9927\n",
      "Epoch 62/100\n",
      "410/410 [==============================] - 0s 172us/step - loss: 0.0159 - acc: 0.9951\n",
      "Epoch 63/100\n",
      "410/410 [==============================] - 0s 171us/step - loss: 0.0151 - acc: 0.9951\n",
      "Epoch 64/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0150 - acc: 0.9951\n",
      "Epoch 65/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0144 - acc: 0.9976\n",
      "Epoch 66/100\n",
      "410/410 [==============================] - 0s 157us/step - loss: 0.0142 - acc: 0.9951\n",
      "Epoch 67/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0142 - acc: 0.9976\n",
      "Epoch 68/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0133 - acc: 0.9976\n",
      "Epoch 69/100\n",
      "410/410 [==============================] - 0s 142us/step - loss: 0.0126 - acc: 0.9976\n",
      "Epoch 70/100\n",
      "410/410 [==============================] - 0s 139us/step - loss: 0.0130 - acc: 0.9951\n",
      "Epoch 71/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0114 - acc: 0.9976\n",
      "Epoch 72/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0112 - acc: 0.9976\n",
      "Epoch 73/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.0106 - acc: 0.9976\n",
      "Epoch 74/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0108 - acc: 0.9976\n",
      "Epoch 75/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0097 - acc: 0.9976\n",
      "Epoch 76/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0087 - acc: 0.9976\n",
      "Epoch 77/100\n",
      "410/410 [==============================] - 0s 141us/step - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 78/100\n",
      "410/410 [==============================] - 0s 132us/step - loss: 0.0085 - acc: 0.9976\n",
      "Epoch 79/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0079 - acc: 0.9976\n",
      "Epoch 80/100\n",
      "410/410 [==============================] - 0s 137us/step - loss: 0.0070 - acc: 0.9976\n",
      "Epoch 81/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0071 - acc: 0.9976\n",
      "Epoch 82/100\n",
      "410/410 [==============================] - 0s 142us/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "410/410 [==============================] - 0s 142us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "410/410 [==============================] - 0s 144us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0051 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0048 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0041 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "410/410 [==============================] - 0s 157us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "410/410 [==============================] - 0s 157us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0038 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "410/410 [==============================] - 0s 165us/step - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "410/410 [==============================] - 0s 159us/step - loss: 0.0034 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "410/410 [==============================] - 0s 162us/step - loss: 0.0032 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0030 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0036 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0028 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "410/410 [==============================] - 0s 159us/step - loss: 0.0026 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0023 - acc: 1.0000\n",
      "Epoch 1/100\n",
      "410/410 [==============================] - 1s 2ms/step - loss: 0.6772 - acc: 0.7024\n",
      "Epoch 2/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.5105 - acc: 0.9317\n",
      "Epoch 3/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.2580 - acc: 0.9463\n",
      "Epoch 4/100\n",
      "410/410 [==============================] - 0s 166us/step - loss: 0.1460 - acc: 0.9659\n",
      "Epoch 5/100\n",
      "410/410 [==============================] - 0s 173us/step - loss: 0.1082 - acc: 0.9683\n",
      "Epoch 6/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0910 - acc: 0.9732\n",
      "Epoch 7/100\n",
      "410/410 [==============================] - 0s 175us/step - loss: 0.0822 - acc: 0.9829\n",
      "Epoch 8/100\n",
      "410/410 [==============================] - 0s 171us/step - loss: 0.0757 - acc: 0.9854\n",
      "Epoch 9/100\n",
      "410/410 [==============================] - 0s 172us/step - loss: 0.0715 - acc: 0.9878\n",
      "Epoch 10/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0676 - acc: 0.9878\n",
      "Epoch 11/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0650 - acc: 0.9878\n",
      "Epoch 12/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0618 - acc: 0.9878\n",
      "Epoch 13/100\n",
      "410/410 [==============================] - 0s 142us/step - loss: 0.0594 - acc: 0.9878\n",
      "Epoch 14/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0577 - acc: 0.9878\n",
      "Epoch 15/100\n",
      "410/410 [==============================] - 0s 165us/step - loss: 0.0560 - acc: 0.9878\n",
      "Epoch 16/100\n",
      "410/410 [==============================] - 0s 151us/step - loss: 0.0547 - acc: 0.9878\n",
      "Epoch 17/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0530 - acc: 0.9878\n",
      "Epoch 18/100\n",
      "410/410 [==============================] - 0s 160us/step - loss: 0.0515 - acc: 0.9878\n",
      "Epoch 19/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0505 - acc: 0.9878\n",
      "Epoch 20/100\n",
      "410/410 [==============================] - 0s 185us/step - loss: 0.0488 - acc: 0.9878\n",
      "Epoch 21/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.0482 - acc: 0.9878\n",
      "Epoch 22/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0472 - acc: 0.9878\n",
      "Epoch 23/100\n",
      "410/410 [==============================] - 0s 159us/step - loss: 0.0456 - acc: 0.9878\n",
      "Epoch 24/100\n",
      "410/410 [==============================] - 0s 171us/step - loss: 0.0446 - acc: 0.9902\n",
      "Epoch 25/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0437 - acc: 0.9878\n",
      "Epoch 26/100\n",
      "410/410 [==============================] - 0s 169us/step - loss: 0.0426 - acc: 0.9902\n",
      "Epoch 27/100\n",
      "410/410 [==============================] - 0s 165us/step - loss: 0.0415 - acc: 0.9902\n",
      "Epoch 28/100\n",
      "410/410 [==============================] - 0s 156us/step - loss: 0.0408 - acc: 0.9902\n",
      "Epoch 29/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0400 - acc: 0.9902\n",
      "Epoch 30/100\n",
      "410/410 [==============================] - 0s 188us/step - loss: 0.0391 - acc: 0.9902\n",
      "Epoch 31/100\n",
      "410/410 [==============================] - 0s 156us/step - loss: 0.0382 - acc: 0.9902\n",
      "Epoch 32/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0372 - acc: 0.9902\n",
      "Epoch 33/100\n",
      "410/410 [==============================] - 0s 158us/step - loss: 0.0369 - acc: 0.9902\n",
      "Epoch 34/100\n",
      "410/410 [==============================] - 0s 170us/step - loss: 0.0359 - acc: 0.9902\n",
      "Epoch 35/100\n",
      "410/410 [==============================] - 0s 160us/step - loss: 0.0353 - acc: 0.9902\n",
      "Epoch 36/100\n",
      "410/410 [==============================] - 0s 162us/step - loss: 0.0342 - acc: 0.9902\n",
      "Epoch 37/100\n",
      "410/410 [==============================] - 0s 172us/step - loss: 0.0336 - acc: 0.9902\n",
      "Epoch 38/100\n",
      "410/410 [==============================] - 0s 177us/step - loss: 0.0326 - acc: 0.9902\n",
      "Epoch 39/100\n",
      "410/410 [==============================] - 0s 157us/step - loss: 0.0321 - acc: 0.9902\n",
      "Epoch 40/100\n",
      "410/410 [==============================] - 0s 172us/step - loss: 0.0313 - acc: 0.9902\n",
      "Epoch 41/100\n",
      "410/410 [==============================] - 0s 186us/step - loss: 0.0306 - acc: 0.9902\n",
      "Epoch 42/100\n",
      "410/410 [==============================] - 0s 165us/step - loss: 0.0308 - acc: 0.9902\n",
      "Epoch 43/100\n",
      "410/410 [==============================] - 0s 156us/step - loss: 0.0290 - acc: 0.9902\n",
      "Epoch 44/100\n",
      "410/410 [==============================] - 0s 158us/step - loss: 0.0284 - acc: 0.9902\n",
      "Epoch 45/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0279 - acc: 0.9902\n",
      "Epoch 46/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0272 - acc: 0.9902\n",
      "Epoch 47/100\n",
      "410/410 [==============================] - 0s 174us/step - loss: 0.0264 - acc: 0.9902\n",
      "Epoch 48/100\n",
      "410/410 [==============================] - 0s 196us/step - loss: 0.0260 - acc: 0.9902\n",
      "Epoch 49/100\n",
      "410/410 [==============================] - 0s 183us/step - loss: 0.0260 - acc: 0.9902\n",
      "Epoch 50/100\n",
      "410/410 [==============================] - 0s 174us/step - loss: 0.0250 - acc: 0.9927\n",
      "Epoch 51/100\n",
      "410/410 [==============================] - 0s 167us/step - loss: 0.0240 - acc: 0.9927\n",
      "Epoch 52/100\n",
      "410/410 [==============================] - 0s 171us/step - loss: 0.0234 - acc: 0.9927\n",
      "Epoch 53/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0233 - acc: 0.9902\n",
      "Epoch 54/100\n",
      "410/410 [==============================] - 0s 178us/step - loss: 0.0223 - acc: 0.9927\n",
      "Epoch 55/100\n",
      "410/410 [==============================] - 0s 167us/step - loss: 0.0217 - acc: 0.9927\n",
      "Epoch 56/100\n",
      "410/410 [==============================] - 0s 160us/step - loss: 0.0215 - acc: 0.9902\n",
      "Epoch 57/100\n",
      "410/410 [==============================] - 0s 156us/step - loss: 0.0208 - acc: 0.9927\n",
      "Epoch 58/100\n",
      "410/410 [==============================] - 0s 156us/step - loss: 0.0207 - acc: 0.9927\n",
      "Epoch 59/100\n",
      "410/410 [==============================] - 0s 165us/step - loss: 0.0207 - acc: 0.9927\n",
      "Epoch 60/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0191 - acc: 0.9927\n",
      "Epoch 61/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0184 - acc: 0.9927\n",
      "Epoch 62/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0183 - acc: 0.9927\n",
      "Epoch 63/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0176 - acc: 0.9951\n",
      "Epoch 64/100\n",
      "410/410 [==============================] - 0s 174us/step - loss: 0.0162 - acc: 0.9927\n",
      "Epoch 65/100\n",
      "410/410 [==============================] - 0s 164us/step - loss: 0.0158 - acc: 0.9927\n",
      "Epoch 66/100\n",
      "410/410 [==============================] - 0s 180us/step - loss: 0.0152 - acc: 0.9951\n",
      "Epoch 67/100\n",
      "410/410 [==============================] - 0s 184us/step - loss: 0.0144 - acc: 0.9951\n",
      "Epoch 68/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0142 - acc: 0.9927\n",
      "Epoch 69/100\n",
      "410/410 [==============================] - 0s 179us/step - loss: 0.0136 - acc: 0.9951\n",
      "Epoch 70/100\n",
      "410/410 [==============================] - 0s 158us/step - loss: 0.0127 - acc: 0.9951\n",
      "Epoch 71/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0122 - acc: 0.9976\n",
      "Epoch 72/100\n",
      "410/410 [==============================] - 0s 150us/step - loss: 0.0113 - acc: 0.9976\n",
      "Epoch 73/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0108 - acc: 0.9951\n",
      "Epoch 74/100\n",
      "410/410 [==============================] - 0s 158us/step - loss: 0.0114 - acc: 0.9951\n",
      "Epoch 75/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0115 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0101 - acc: 0.9976\n",
      "Epoch 77/100\n",
      "410/410 [==============================] - 0s 165us/step - loss: 0.0101 - acc: 0.9951\n",
      "Epoch 78/100\n",
      "410/410 [==============================] - 0s 180us/step - loss: 0.0090 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "410/410 [==============================] - 0s 173us/step - loss: 0.0098 - acc: 0.9951\n",
      "Epoch 80/100\n",
      "410/410 [==============================] - 0s 152us/step - loss: 0.0111 - acc: 0.9976\n",
      "Epoch 81/100\n",
      "410/410 [==============================] - 0s 164us/step - loss: 0.0117 - acc: 0.9976\n",
      "Epoch 82/100\n",
      "410/410 [==============================] - 0s 157us/step - loss: 0.0090 - acc: 0.9976\n",
      "Epoch 83/100\n",
      "410/410 [==============================] - 0s 170us/step - loss: 0.0079 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "410/410 [==============================] - 0s 164us/step - loss: 0.0076 - acc: 0.9976\n",
      "Epoch 85/100\n",
      "410/410 [==============================] - 0s 157us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "410/410 [==============================] - 0s 159us/step - loss: 0.0066 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "410/410 [==============================] - 0s 154us/step - loss: 0.0067 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "410/410 [==============================] - 0s 161us/step - loss: 0.0058 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "410/410 [==============================] - 0s 179us/step - loss: 0.0057 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0055 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "410/410 [==============================] - 0s 156us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "410/410 [==============================] - 0s 162us/step - loss: 0.0050 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "410/410 [==============================] - 0s 159us/step - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "410/410 [==============================] - 0s 170us/step - loss: 0.0054 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "410/410 [==============================] - 0s 158us/step - loss: 0.0044 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "410/410 [==============================] - 0s 167us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "410/410 [==============================] - 0s 156us/step - loss: 0.0042 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "410/410 [==============================] - 0s 165us/step - loss: 0.0040 - acc: 1.0000\n",
      "Epoch 1/100\n",
      "410/410 [==============================] - 1s 2ms/step - loss: 0.6792 - acc: 0.7878\n",
      "Epoch 2/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.5122 - acc: 0.9463\n",
      "Epoch 3/100\n",
      "410/410 [==============================] - 0s 134us/step - loss: 0.2227 - acc: 0.9585\n",
      "Epoch 4/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.1270 - acc: 0.9683\n",
      "Epoch 5/100\n",
      "410/410 [==============================] - 0s 153us/step - loss: 0.0981 - acc: 0.9732\n",
      "Epoch 6/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0835 - acc: 0.9854\n",
      "Epoch 7/100\n",
      "410/410 [==============================] - 0s 137us/step - loss: 0.0755 - acc: 0.9854\n",
      "Epoch 8/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0704 - acc: 0.9854\n",
      "Epoch 9/100\n",
      "410/410 [==============================] - 0s 142us/step - loss: 0.0662 - acc: 0.9854\n",
      "Epoch 10/100\n",
      "410/410 [==============================] - 0s 155us/step - loss: 0.0633 - acc: 0.9854\n",
      "Epoch 11/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0614 - acc: 0.9878\n",
      "Epoch 12/100\n",
      "410/410 [==============================] - 0s 134us/step - loss: 0.0589 - acc: 0.9878\n",
      "Epoch 13/100\n",
      "410/410 [==============================] - 0s 139us/step - loss: 0.0568 - acc: 0.9878\n",
      "Epoch 14/100\n",
      "410/410 [==============================] - 0s 146us/step - loss: 0.0549 - acc: 0.9878\n",
      "Epoch 15/100\n",
      "410/410 [==============================] - 0s 134us/step - loss: 0.0535 - acc: 0.9878\n",
      "Epoch 16/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0518 - acc: 0.9878\n",
      "Epoch 17/100\n",
      "410/410 [==============================] - 0s 145us/step - loss: 0.0506 - acc: 0.9878\n",
      "Epoch 18/100\n",
      "410/410 [==============================] - 0s 143us/step - loss: 0.0496 - acc: 0.9878\n",
      "Epoch 19/100\n",
      "410/410 [==============================] - 0s 148us/step - loss: 0.0478 - acc: 0.9878\n",
      "Epoch 20/100\n",
      "410/410 [==============================] - 0s 163us/step - loss: 0.0470 - acc: 0.9878\n",
      "Epoch 21/100\n",
      "410/410 [==============================] - 0s 159us/step - loss: 0.0461 - acc: 0.9878\n",
      "Epoch 22/100\n",
      "410/410 [==============================] - 0s 149us/step - loss: 0.0447 - acc: 0.9878\n",
      "Epoch 23/100\n",
      "410/410 [==============================] - 0s 160us/step - loss: 0.0432 - acc: 0.9878\n",
      "Epoch 24/100\n",
      "410/410 [==============================] - 0s 162us/step - loss: 0.0418 - acc: 0.9902\n",
      "Epoch 25/100\n",
      "410/410 [==============================] - 0s 158us/step - loss: 0.0409 - acc: 0.9878\n",
      "Epoch 26/100\n",
      "410/410 [==============================] - 0s 157us/step - loss: 0.0401 - acc: 0.9902\n",
      "Epoch 27/100\n",
      "410/410 [==============================] - 0s 156us/step - loss: 0.0390 - acc: 0.9902\n",
      "Epoch 28/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0374 - acc: 0.9902\n",
      "Epoch 29/100\n",
      "410/410 [==============================] - 0s 147us/step - loss: 0.0367 - acc: 0.9902\n",
      "Epoch 30/100\n",
      "410/410 [==============================] - 0s 144us/step - loss: 0.0360 - acc: 0.9902\n",
      "Epoch 31/100\n",
      "410/410 [==============================] - 0s 142us/step - loss: 0.0349 - acc: 0.9902\n",
      "Epoch 32/100\n",
      "410/410 [==============================] - 0s 136us/step - loss: 0.0339 - acc: 0.9902\n",
      "Epoch 33/100\n",
      " 10/410 [..............................] - ETA: 0s - loss: 0.0178 - acc: 1.0000"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "def built_classifier(optimizer = 'adam'):\n",
    "  classifier = Sequential()\n",
    "  classifier.add(Dense(output_dim=16, init='uniform', activation='relu',input_dim=30))\n",
    "  classifier.add(Dense(output_dim=16, init='uniform', activation='relu'))\n",
    "  classifier.add(Dense(output_dim=1, init='uniform', activation='sigmoid'))\n",
    "  classifier.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "  return classifier\n",
    "\n",
    "classifier = KerasClassifier(build_fn = built_classifier)\n",
    "parameters = {'batch_size': [10, 32],'epochs': [100, 500],'optimizer': ['adam', 'rmsprop']}\n",
    "grid_search = GridSearchCV(estimator = classifier, param_grid = parameters, scoring = 'accuracy',\n",
    "                           cv = 10)\n",
    "\n",
    "grid_search = grid_search.fit(X_train, y_train)\n",
    "best_parameters = grid_search.best_params_\n",
    "best_accuracy = grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "colab_type": "code",
    "id": "rrAdjhIyb_hp",
    "outputId": "2ebef79e-217a-4c3a-fb5c-060cb2e16d3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:530: FutureWarning: From version 0.22, errors during fit will result in a cross validation score of NaN by default. Use error_score='raise' if you want an exception raised or error_score=np.nan to adopt the behavior from version 0.22.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-3135f9767e84>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m                            cv = 10)\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mgrid_search\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mbest_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mbest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    686\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1149\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    665\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 667\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    668\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1002\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    833\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 754\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    207\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 209\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    210\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 256\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    514\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 516\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    517\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    518\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sample_weight'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 **self.filter_sk_params(self.build_fn.__call__))\n\u001b[1;32m    140\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0mloss_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-eedf58920c08>\u001b[0m in \u001b[0;36mbuild_classifier\u001b[0;34m(optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mclassifierdel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KerasClassifier' object has no attribute 'add'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6xbpsj9mY0Xo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Classification_ANN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
